{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ddfafd",
   "metadata": {},
   "source": [
    "# Torch DQN \n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94604268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asong18\\Anaconda3\\envs\\deeplearning3.7\\lib\\site-packages\\gym\\envs\\registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment maze-v0\u001b[0m\n",
      "  logger.warn(\"Overriding environment {}\".format(id))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "set the target x to 162\n",
      "set the target y to 136\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import gym\n",
    "import gym_child\n",
    "import gym_teen\n",
    "#import gym_child_grayscale\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# Load a FOV grabber for pelvis. \n",
    "#env = gym.make('maze-v0')\n",
    "\n",
    "# This is the new distance metric reward function.\n",
    "env = gym.make('maze-v0',height=60,width=60)#,target_x = 162, target_y = 136)\n",
    "env.set_target_xy(x = 162, y = 136)\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77da3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee579dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7db963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dueling DQN. \n",
    "class Dueling_DQN(nn.Module):\n",
    "    def __init__(self, in_channels, num_actions):\n",
    "        super(Dueling_DQN, self).__init__()\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.fc1_adv = nn.Linear(in_features=7*7*64, out_features=512)\n",
    "        self.fc1_val = nn.Linear(in_features=7*7*64, out_features=512)\n",
    "\n",
    "        self.fc2_adv = nn.Linear(in_features=512, out_features=num_actions)\n",
    "        self.fc2_val = nn.Linear(in_features=512, out_features=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        adv = self.relu(self.fc1_adv(x))\n",
    "        val = self.relu(self.fc1_val(x))\n",
    "\n",
    "        adv = self.fc2_adv(adv)\n",
    "        val = self.fc2_val(val).expand(x.size(0), self.num_actions)\n",
    "        \n",
    "        x = val + adv - adv.mean(1).unsqueeze(1).expand(x.size(0), self.num_actions)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ee9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asong18\\Anaconda3\\envs\\deeplearning3.7\\lib\\site-packages\\torchvision\\transforms\\transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 405x405x3, but is sometimes larger\n",
    "    # Transpose it into torch order (CHW).\n",
    "    screen = env.render().transpose((2, 0, 1))\n",
    "\n",
    "    # # Convert to float, rescale, convert to torch tensor\n",
    "    # # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80717c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 5\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "print(init_screen.shape)\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())#,lr=0.01)\n",
    "\n",
    "# Adam Optimizer \n",
    "#optimizer = optim.Adam(policy_net.parameters(),lr=0.01)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "# episode_durations = []\n",
    "\n",
    "# def plot_durations():\n",
    "#     plt.figure(2)\n",
    "#     plt.clf()\n",
    "#     durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "#     plt.title('Training...')\n",
    "#     plt.xlabel('Episode')\n",
    "#     plt.ylabel('Duration')\n",
    "#     plt.plot(durations_t.numpy())\n",
    "#     # Take 100 episode averages and plot them too\n",
    "#     if len(durations_t) >= 100:\n",
    "#         means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "#         means = torch.cat((torch.zeros(99), means))\n",
    "#         plt.plot(means.numpy())\n",
    "\n",
    "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "#     if is_ipython:\n",
    "#         display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb386a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96ac6d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MazeView2D' object has no attribute 'target_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17592\\1432721759.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Select and perform an action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning3.7\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\asong18\\Desktop\\Deep_RL_View_Planning\\CT_View_Planning_DeepRL\\gym-child_thresholded_NN\\gym_teen\\envs\\maze_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# D(P_{i-1}, P_t)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mdistance_current\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meuclidean_distance_from_goal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdistance_current\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_current\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\asong18\\Desktop\\Deep_RL_View_Planning\\CT_View_Planning_DeepRL\\gym-child_thresholded_NN\\gym_teen\\envs\\maze_view_2d.py\u001b[0m in \u001b[0;36meuclidean_distance_from_goal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;31m# self.y = int(self.__robot[1]+1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[1;32mreturn\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MazeView2D' object has no attribute 'target_x'"
     ]
    }
   ],
   "source": [
    "num_episodes = 40\n",
    "#num_episodes = 5 \n",
    "training_loss = []\n",
    "training_reward = []\n",
    "training_steps = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    episode_loss = 0.0\n",
    "    episode_reward = 0.0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        episode_reward+= reward.item()\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        \n",
    "        step_loss = optimize_model()\n",
    "        if step_loss is not None:\n",
    "            episode_loss += step_loss.item()\n",
    "        \n",
    "        if done:\n",
    "            # episode_durations.append(t + 1)\n",
    "            # plot_durations()\n",
    "            training_steps.append(t+1)\n",
    "            \n",
    "            if episode_loss is not None:\n",
    "                training_loss.append(episode_loss)\n",
    "            \n",
    "            training_reward.append(episode_reward)\n",
    "\n",
    "            print(f\"Just finished Episode {i_episode} in {t+1} steps, with reward {episode_reward}!\")\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "# save model. \n",
    "torch.save(policy_net.state_dict(), f\"policy_network_gymTEEN_distanceReward_{num_episodes}episodes.pkl\")\n",
    "# save model. \n",
    "torch.save(target_net.state_dict(), f\"target_network_gymTEEN_distanceReward_{num_episodes}episodes.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171ce102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 140)\n",
      "current distance is: 14.560219778561036, and future distance is 5.656854249492381\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 0 in 273 steps!\n",
      "(168, 135)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 1 in 314 steps!\n",
      "(161, 142)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 2 in 219 steps!\n",
      "(163, 137)\n",
      "current distance is: 11.045361017187261, and future distance is 1.4142135623730951\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 3 in 76 steps!\n",
      "(165, 141)\n",
      "current distance is: 13.92838827718412, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 4 in 31 steps!\n",
      "(165, 137)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 5 in 161 steps!\n",
      "(162, 141)\n",
      "current distance is: 11.180339887498949, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 6 in 188 steps!\n",
      "(156, 144)\n",
      "current distance is: 17.88854381999832, and future distance is 10.0\n",
      "Just finished Episode 7 in 19 steps!\n",
      "(168, 133)\n",
      "current distance is: 16.278820596099706, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 8 in 283 steps!\n",
      "(156, 143)\n",
      "current distance is: 17.46424919657298, and future distance is 9.219544457292887\n",
      "Just finished Episode 9 in 30 steps!\n",
      "(164, 143)\n",
      "current distance is: 13.892443989449804, and future distance is 7.280109889280518\n",
      "Just finished Episode 10 in 55 steps!\n",
      "(154, 131)\n",
      "current distance is: 17.0, and future distance is 9.433981132056603\n",
      "Just finished Episode 11 in 15 steps!\n",
      "(162, 142)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 12 in 377 steps!\n",
      "(156, 136)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 13 in 242 steps!\n",
      "(161, 144)\n",
      "current distance is: 13.601470508735444, and future distance is 8.06225774829855\n",
      "Just finished Episode 14 in 7 steps!\n",
      "(165, 142)\n",
      "current distance is: 14.317821063276353, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 15 in 289 steps!\n",
      "(170, 133)\n",
      "current distance is: 18.24828759089466, and future distance is 8.54400374531753\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 16 in 281 steps!\n",
      "(165, 143)\n",
      "current distance is: 14.7648230602334, and future distance is 7.615773105863909\n",
      "Just finished Episode 17 in 157 steps!\n",
      "(168, 138)\n",
      "current distance is: 16.1245154965971, and future distance is 6.324555320336759\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 18 in 150 steps!\n",
      "(158, 131)\n",
      "current distance is: 15.524174696260024, and future distance is 6.4031242374328485\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 19 in 119 steps!\n",
      "(170, 134)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 20 in 35 steps!\n",
      "(161, 139)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 21 in 84 steps!\n",
      "(166, 136)\n",
      "current distance is: 14.0, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 22 in 92 steps!\n",
      "(164, 137)\n",
      "current distance is: 12.041594578792296, and future distance is 2.23606797749979\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 23 in 217 steps!\n",
      "(154, 137)\n",
      "current distance is: 18.027756377319946, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 24 in 136 steps!\n",
      "(171, 134)\n",
      "current distance is: 15.0, and future distance is 9.219544457292887\n",
      "Just finished Episode 25 in 190 steps!\n",
      "(153, 137)\n",
      "current distance is: 19.026297590440446, and future distance is 9.055385138137417\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 26 in 28 steps!\n",
      "(171, 136)\n",
      "current distance is: 13.45362404707371, and future distance is 9.0\n",
      "Just finished Episode 27 in 82 steps!\n",
      "(163, 144)\n",
      "current distance is: 13.601470508735444, and future distance is 8.06225774829855\n",
      "Just finished Episode 28 in 352 steps!\n",
      "(156, 129)\n",
      "current distance is: 18.027756377319946, and future distance is 9.219544457292887\n",
      "Just finished Episode 29 in 32 steps!\n",
      "(162, 132)\n",
      "current distance is: 10.770329614269007, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 30 in 858 steps!\n",
      "(158, 134)\n",
      "current distance is: 12.649110640673518, and future distance is 4.47213595499958\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 31 in 4 steps!\n",
      "(163, 131)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 32 in 36 steps!\n",
      "(162, 132)\n",
      "current distance is: 10.770329614269007, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 33 in 302 steps!\n",
      "(154, 138)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 34 in 293 steps!\n",
      "(165, 136)\n",
      "current distance is: 10.44030650891055, and future distance is 3.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 35 in 403 steps!\n",
      "(163, 133)\n",
      "current distance is: 11.40175425099138, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 36 in 21 steps!\n",
      "(163, 140)\n",
      "current distance is: 11.704699910719626, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 37 in 488 steps!\n",
      "(161, 143)\n",
      "current distance is: 11.40175425099138, and future distance is 7.0710678118654755\n",
      "Just finished Episode 38 in 68 steps!\n",
      "(171, 137)\n",
      "current distance is: 14.212670403551895, and future distance is 9.055385138137417\n",
      "Just finished Episode 39 in 264 steps!\n",
      "(165, 145)\n",
      "current distance is: 15.811388300841896, and future distance is 9.486832980505138\n",
      "Just finished Episode 40 in 51 steps!\n",
      "(163, 137)\n",
      "current distance is: 11.045361017187261, and future distance is 1.4142135623730951\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 41 in 51 steps!\n",
      "(165, 137)\n",
      "current distance is: 11.40175425099138, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 42 in 144 steps!\n",
      "(170, 133)\n",
      "current distance is: 18.24828759089466, and future distance is 8.54400374531753\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 43 in 170 steps!\n",
      "(155, 136)\n",
      "current distance is: 12.206555615733702, and future distance is 7.0\n",
      "Just finished Episode 44 in 218 steps!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 45 in 42 steps!\n",
      "(155, 130)\n",
      "current distance is: 17.46424919657298, and future distance is 9.219544457292887\n",
      "Just finished Episode 46 in 13 steps!\n",
      "(167, 138)\n",
      "current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 47 in 48 steps!\n",
      "(162, 145)\n",
      "current distance is: 13.45362404707371, and future distance is 9.0\n",
      "Just finished Episode 48 in 90 steps!\n",
      "(162, 138)\n",
      "current distance is: 10.198039027185569, and future distance is 2.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 49 in 174 steps!\n",
      "(170, 138)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 50 in 59 steps!\n",
      "(155, 131)\n",
      "current distance is: 16.55294535724685, and future distance is 8.602325267042627\n",
      "Just finished Episode 51 in 14 steps!\n",
      "(156, 138)\n",
      "current distance is: 13.416407864998739, and future distance is 6.324555320336759\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 52 in 115 steps!\n",
      "(171, 140)\n",
      "current distance is: 16.64331697709324, and future distance is 9.848857801796104\n",
      "Just finished Episode 53 in 176 steps!\n",
      "(164, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 54 in 42 steps!\n",
      "(169, 141)\n",
      "current distance is: 17.72004514666935, and future distance is 8.602325267042627\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 55 in 86 steps!\n",
      "(168, 138)\n",
      "current distance is: 16.1245154965971, and future distance is 6.324555320336759\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 56 in 13 steps!\n",
      "(155, 129)\n",
      "current distance is: 18.384776310850235, and future distance is 9.899494936611665\n",
      "Just finished Episode 57 in 124 steps!\n",
      "(157, 140)\n",
      "current distance is: 14.866068747318506, and future distance is 6.4031242374328485\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 58 in 36 steps!\n",
      "(161, 141)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 59 in 334 steps!\n",
      "(166, 136)\n",
      "current distance is: 14.0, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 60 in 121 steps!\n",
      "(164, 136)\n",
      "current distance is: 10.198039027185569, and future distance is 2.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 61 in 18 steps!\n",
      "(166, 133)\n",
      "current distance is: 14.317821063276353, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 62 in 514 steps!\n",
      "(157, 135)\n",
      "current distance is: 10.295630140987, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 63 in 225 steps!\n",
      "(166, 135)\n",
      "current distance is: 14.035668847618199, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 64 in 146 steps!\n",
      "(165, 133)\n",
      "current distance is: 13.341664064126334, and future distance is 4.242640687119285\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 65 in 164 steps!\n",
      "(165, 139)\n",
      "current distance is: 13.341664064126334, and future distance is 4.242640687119285\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 66 in 53 steps!\n",
      "(163, 138)\n",
      "current distance is: 12.041594578792296, and future distance is 2.23606797749979\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 67 in 111 steps!\n",
      "(167, 139)\n",
      "current distance is: 15.297058540778355, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 68 in 97 steps!\n",
      "(162, 142)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 69 in 929 steps!\n",
      "(170, 139)\n",
      "current distance is: 18.24828759089466, and future distance is 8.54400374531753\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 70 in 122 steps!\n",
      "(164, 145)\n",
      "current distance is: 12.041594578792296, and future distance is 9.219544457292887\n",
      "Just finished Episode 71 in 24 steps!\n",
      "(156, 133)\n",
      "current distance is: 14.317821063276353, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 72 in 4 steps!\n",
      "(157, 136)\n",
      "current distance is: 11.180339887498949, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 73 in 40 steps!\n",
      "(161, 141)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 74 in 468 steps!\n",
      "(167, 136)\n",
      "current distance is: 15.0, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 75 in 34 steps!\n",
      "(165, 144)\n",
      "current distance is: 10.63014581273465, and future distance is 8.54400374531753\n",
      "Just finished Episode 76 in 21 steps!\n",
      "(170, 138)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 77 in 46 steps!\n",
      "(163, 141)\n",
      "current distance is: 12.083045973594572, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 78 in 94 steps!\n",
      "(161, 141)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 79 in 164 steps!\n",
      "(160, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 80 in 66 steps!\n",
      "(159, 127)\n",
      "current distance is: 19.235384061671343, and future distance is 9.486832980505138\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 81 in 5 steps!\n",
      "(170, 139)\n",
      "current distance is: 18.24828759089466, and future distance is 8.54400374531753\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 82 in 349 steps!\n",
      "(157, 135)\n",
      "current distance is: 10.295630140987, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 83 in 133 steps!\n",
      "(166, 141)\n",
      "current distance is: 14.866068747318506, and future distance is 6.4031242374328485\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 84 in 80 steps!\n",
      "(160, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 85 in 182 steps!\n",
      "(164, 142)\n",
      "current distance is: 13.416407864998739, and future distance is 6.324555320336759\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 86 in 125 steps!\n",
      "(154, 138)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 87 in 48 steps!\n",
      "(167, 137)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 88 in 73 steps!\n",
      "(161, 139)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 89 in 241 steps!\n",
      "(168, 138)\n",
      "current distance is: 16.1245154965971, and future distance is 6.324555320336759\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 90 in 76 steps!\n",
      "(164, 144)\n",
      "current distance is: 11.313708498984761, and future distance is 8.246211251235321\n",
      "Just finished Episode 91 in 8 steps!\n",
      "(156, 130)\n",
      "current distance is: 17.08800749063506, and future distance is 8.48528137423857\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 92 in 31 steps!\n",
      "(157, 143)\n",
      "current distance is: 16.55294535724685, and future distance is 8.602325267042627\n",
      "Just finished Episode 93 in 9 steps!\n",
      "(167, 141)\n",
      "current distance is: 15.811388300841896, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 94 in 157 steps!\n",
      "(162, 140)\n",
      "current distance is: 14.0, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 95 in 93 steps!\n",
      "(165, 137)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 96 in 27 steps!\n",
      "(162, 142)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 97 in 760 steps!\n",
      "(158, 142)\n",
      "current distance is: 16.492422502470642, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 98 in 10 steps!\n",
      "(166, 139)\n",
      "current distance is: 14.317821063276353, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 99 in 425 steps!\n",
      "Average Testing Steps for 100 episodes is 155.64\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 100\n",
    "total_test_steps = 0\n",
    "for i_episode in range(test_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            total_test_steps +=t+1\n",
    "\n",
    "            print(f\"Just finished Episode {i_episode} in {t+1} steps!\")\n",
    "            break\n",
    "\n",
    "print(f\"Average Testing Steps for 100 episodes is {total_test_steps / test_episodes}\")\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e658122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# length = len(fit.history['nb_episode_steps'])\n",
    "length = num_episodes\n",
    "fig = plt.figure()\n",
    "#plt.title(\"Reward and Steps to Goal vs. Episodes\")\n",
    "ax = fig.add_subplot(111, label=\"1\")\n",
    "ax2 = fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "ax.plot(range(length), training_steps, color=\"C0\")\n",
    "ax.set_xlabel(\"Episodes\", color=\"C0\")\n",
    "ax.set_ylabel(\"Total Steps\", color=\"C0\")\n",
    "ax.tick_params(axis='x', colors=\"C0\")\n",
    "ax.tick_params(axis='y', colors=\"C0\")\n",
    "ax2.scatter(range(length), training_reward, color=\"C1\")\n",
    "ax2.axes.get_xaxis().set_visible(False)\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel('Episode Reward', color=\"C1\")\n",
    "ax2.yaxis.set_label_position('right')\n",
    "ax2.tick_params(axis='y', colors=\"C1\")\n",
    "ax.set_title(\"Reward and Steps to Goal vs. Episodes\")\n",
    "fig.savefig(f\"Grayscale_Deep_Q_learn_ConvNet_{length}eps_DistanceMetric\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
