{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ddfafd",
   "metadata": {},
   "source": [
    "# Torch DQN \n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94604268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "set the target x to 162\n",
      "set the target y to 136\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# # Load a FOV grabber for pelvis. \n",
    "# import gym_child\n",
    "# env = gym.make('maze-v0')\n",
    "# environment_type = \"thresholded\"\n",
    "\n",
    "#This is the new distance metric reward function.\n",
    "import gym_teen\n",
    "env = gym.make('maze-v0',height=60,width=60)#,target_x = 162, target_y = 136)\n",
    "env.set_target_xy(x = 162, y = 136)\n",
    "environment_type = \"grayscale\"\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77da3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30f0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Fully_Connected(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN_Fully_Connected, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(h* w * 3, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, outputs)\n",
    "\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee579dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN_Conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7db963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dueling DQN. IMPLEMENTATION IS INCORRECT.  \n",
    "class Dueling_DQN(nn.Module):\n",
    "    def __init__(self, h,w, num_actions):\n",
    "        super(Dueling_DQN, self).__init__()\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=2)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "\n",
    "\n",
    "        self.fc1_adv = nn.Linear(in_features=linear_input_size, out_features=512)\n",
    "        self.fc1_val = nn.Linear(in_features=linear_input_size, out_features=512)\n",
    "\n",
    "        self.fc2_adv = nn.Linear(in_features=512, out_features=num_actions)\n",
    "        self.fc2_val = nn.Linear(in_features=512, out_features=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size = x.size(0)\n",
    "        x = x.to(device)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        adv = self.relu(self.fc1_adv(x))\n",
    "        val = self.relu(self.fc1_val(x))\n",
    "\n",
    "        adv = self.fc2_adv(adv)\n",
    "        val = self.fc2_val(val).expand(x.size(0), self.num_actions)\n",
    "        \n",
    "        x = val + adv - adv.mean(1).unsqueeze(1).expand(x.size(0), self.num_actions)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ee9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asong18\\Anaconda3\\envs\\deeplearning3.7\\lib\\site-packages\\torchvision\\transforms\\transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 405x405x3, but is sometimes larger\n",
    "    # Transpose it into torch order (CHW).\n",
    "    screen = env.render().transpose((2, 0, 1))\n",
    "\n",
    "    # # Convert to float, rescale, convert to torch tensor\n",
    "    # # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80717c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 5\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "print(init_screen.shape)\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "\n",
    "# Regular DQN Fully Convolutional\n",
    "policy_net = DQN_Fully_Connected(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN_Fully_Connected(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "model_type = \"FC-DQN\"\n",
    "\n",
    "# # Regular DQN Convnet\n",
    "# policy_net = DQN_Conv(screen_height, screen_width, n_actions).to(device)\n",
    "# target_net = DQN_Conv(screen_height, screen_width, n_actions).to(device)\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "# model_type = \"Conv-DQN\"\n",
    "\n",
    "# # # Dueling DQN \n",
    "# policy_net = Dueling_DQN(screen_height, screen_width, n_actions).to(device)\n",
    "# target_net = Dueling_DQN(screen_height, screen_width, n_actions).to(device)\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "# model_type = \"Dueling-DQN\"\n",
    "\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())#,lr=0.01)\n",
    "\n",
    "# Adam Optimizer \n",
    "#optimizer = optim.Adam(policy_net.parameters(),lr=0.0002)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "# episode_durations = []\n",
    "\n",
    "# def plot_durations():\n",
    "#     plt.figure(2)\n",
    "#     plt.clf()\n",
    "#     durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "#     plt.title('Training...')\n",
    "#     plt.xlabel('Episode')\n",
    "#     plt.ylabel('Duration')\n",
    "#     plt.plot(durations_t.numpy())\n",
    "#     # Take 100 episode averages and plot them too\n",
    "#     if len(durations_t) >= 100:\n",
    "#         means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "#         means = torch.cat((torch.zeros(99), means))\n",
    "#         plt.plot(means.numpy())\n",
    "\n",
    "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "#     if is_ipython:\n",
    "#         display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb386a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96ac6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 141)\n",
      "current distance is: 16.15549442140351, and future distance is 7.810249675906654\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 0 in 171 steps, with reward 11.0!\n",
      "(153, 132)\n",
      "current distance is: 19.4164878389476, and future distance is 9.848857801796104\n",
      "Just finished Episode 1 in 49 steps, with reward 5.0!\n",
      "(164, 135)\n",
      "current distance is: 12.041594578792296, and future distance is 2.23606797749979\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 2 in 16 steps, with reward 6.0!\n",
      "(150, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.0, and future distance is 13.416407864998739\n",
      "Just finished Episode 3 in 53 steps, with reward 21.0!\n",
      "(157, 139)\n",
      "current distance is: 15.297058540778355, and future distance is 5.830951894845301\n",
      "(157, 139)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 15.297058540778355, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 4 in 7 steps, with reward 3.0!\n",
      "(153, 137)\n",
      "current distance is: 14.212670403551895, and future distance is 9.055385138137417\n",
      "Just finished Episode 5 in 25 steps, with reward 17.0!\n",
      "(154, 136)\n",
      "current distance is: 12.806248474865697, and future distance is 8.0\n",
      "Just finished Episode 6 in 36 steps, with reward 18.0!\n",
      "(165, 140)\n",
      "current distance is: 14.317821063276353, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 7 in 26 steps, with reward 18.0!\n",
      "(164, 127)\n",
      "current distance is: 15.0, and future distance is 9.219544457292887\n",
      "Just finished Episode 8 in 50 steps, with reward 14.0!\n",
      "(161, 139)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 9 in 39 steps, with reward 21.0!\n",
      "(169, 135)\n",
      "current distance is: 11.40175425099138, and future distance is 7.0710678118654755\n",
      "Just finished Episode 10 in 5 steps, with reward 5.0!\n",
      "(166, 130)\n",
      "current distance is: 15.231546211727817, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 11 in 57 steps, with reward 1.0!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 12 in 6 steps, with reward 2.0!\n",
      "(170, 133)\n",
      "current distance is: 18.24828759089466, and future distance is 8.54400374531753\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 13 in 56 steps, with reward 28.0!\n",
      "(170, 133)\n",
      "current distance is: 10.63014581273465, and future distance is 8.54400374531753\n",
      "Just finished Episode 14 in 112 steps, with reward 8.0!\n",
      "(170, 137)\n",
      "current distance is: 18.027756377319946, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 15 in 13 steps, with reward 11.0!\n",
      "(163, 135)\n",
      "current distance is: 11.045361017187261, and future distance is 1.4142135623730951\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 16 in 160 steps, with reward 27.0!\n",
      "(165, 130)\n",
      "current distance is: 14.317821063276353, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 17 in 361 steps, with reward 26.0!\n",
      "(163, 133)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 18 in 112 steps, with reward 26.0!\n",
      "(157, 130)\n",
      "current distance is: 16.15549442140351, and future distance is 7.810249675906654\n",
      "(157, 130)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 16.15549442140351, and future distance is 7.810249675906654\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 19 in 68 steps, with reward 2.0!\n",
      "(164, 128)\n",
      "current distance is: 14.422205101855956, and future distance is 8.246211251235321\n",
      "Just finished Episode 20 in 97 steps, with reward 7.0!\n",
      "(159, 145)\n",
      "current distance is: 11.40175425099138, and future distance is 9.486832980505138\n",
      "Just finished Episode 21 in 36 steps, with reward 14.0!\n",
      "(170, 133)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 22 in 14 steps, with reward 12.0!\n",
      "(152, 128)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 21.540659228538015, and future distance is 12.806248474865697\n",
      "Just finished Episode 23 in 30 steps, with reward 12.0!\n",
      "(161, 144)\n",
      "current distance is: 13.601470508735444, and future distance is 8.06225774829855\n",
      "Just finished Episode 24 in 37 steps, with reward 23.0!\n",
      "(159, 142)\n",
      "current distance is: 14.317821063276353, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 25 in 85 steps, with reward 11.0!\n",
      "(164, 134)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 26 in 33 steps, with reward 15.0!\n",
      "(165, 140)\n",
      "current distance is: 14.317821063276353, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 27 in 35 steps, with reward 9.0!\n",
      "(152, 144)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 21.540659228538015, and future distance is 12.806248474865697\n",
      "Just finished Episode 28 in 26 steps, with reward 8.0!\n",
      "(154, 139)\n",
      "current distance is: 10.63014581273465, and future distance is 8.54400374531753\n",
      "Just finished Episode 29 in 6 steps, with reward 6.0!\n",
      "(168, 136)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 30 in 32 steps, with reward 10.0!\n",
      "(165, 142)\n",
      "current distance is: 14.317821063276353, and future distance is 6.708203932499369\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 31 in 92 steps, with reward 16.0!\n",
      "(162, 146)\n",
      "current distance is: 14.142135623730951, and future distance is 10.0\n",
      "Just finished Episode 32 in 73 steps, with reward 19.0!\n",
      "(165, 135)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 33 in 626 steps, with reward 22.0!\n",
      "(164, 147)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 21.095023109728988, and future distance is 11.180339887498949\n",
      "Just finished Episode 34 in 22 steps, with reward 12.0!\n",
      "(169, 137)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 35 in 24 steps, with reward 6.0!\n",
      "(169, 135)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 36 in 17 steps, with reward 13.0!\n",
      "(153, 140)\n",
      "current distance is: 10.816653826391969, and future distance is 9.848857801796104\n",
      "Just finished Episode 37 in 258 steps, with reward 20.0!\n",
      "(155, 133)\n",
      "current distance is: 14.7648230602334, and future distance is 7.615773105863909\n",
      "Just finished Episode 38 in 408 steps, with reward 18.0!\n",
      "(156, 132)\n",
      "current distance is: 15.231546211727817, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 39 in 299 steps, with reward 9.0!\n",
      "(149, 135)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 23.021728866442675, and future distance is 13.038404810405298\n",
      "Just finished Episode 40 in 56 steps, with reward 10.0!\n",
      "(165, 146)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.223748416156685, and future distance is 10.44030650891055\n",
      "Just finished Episode 41 in 801 steps, with reward 13.0!\n",
      "(166, 141)\n",
      "current distance is: 15.524174696260024, and future distance is 6.4031242374328485\n",
      "(166, 141)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 15.524174696260024, and future distance is 6.4031242374328485\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 42 in 594 steps, with reward 8.0!\n",
      "(167, 136)\n",
      "current distance is: 11.180339887498949, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 43 in 76 steps, with reward 24.0!\n",
      "(149, 138)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.69180601295413, and future distance is 13.152946437965905\n",
      "Just finished Episode 44 in 227 steps, with reward 7.0!\n",
      "(157, 139)\n",
      "current distance is: 15.297058540778355, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 45 in 126 steps, with reward 25.0!\n",
      "(169, 141)\n",
      "current distance is: 17.72004514666935, and future distance is 8.602325267042627\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 46 in 55 steps, with reward 19.0!\n",
      "(158, 127)\n",
      "current distance is: 16.64331697709324, and future distance is 9.848857801796104\n",
      "Just finished Episode 47 in 2147 steps, with reward 11.0!\n",
      "(150, 134)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 22.090722034374522, and future distance is 12.165525060596439\n",
      "Just finished Episode 48 in 678 steps, with reward 14.0!\n",
      "(166, 127)\n",
      "current distance is: 19.4164878389476, and future distance is 9.848857801796104\n",
      "Just finished Episode 49 in 152 steps, with reward 2.0!\n",
      "(167, 144)\n",
      "current distance is: 17.0, and future distance is 9.433981132056603\n",
      "Just finished Episode 50 in 254 steps, with reward 8.0!\n",
      "(161, 132)\n",
      "current distance is: 14.035668847618199, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 51 in 111 steps, with reward 27.0!\n",
      "(169, 146)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 21.18962010041709, and future distance is 12.206555615733702\n",
      "Just finished Episode 52 in 769 steps, with reward 11.0!\n",
      "(166, 136)\n",
      "current distance is: 14.0, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 53 in 166 steps, with reward 8.0!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 54 in 97 steps, with reward 13.0!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 55 in 212 steps, with reward 18.0!\n",
      "(161, 131)\n",
      "current distance is: 12.083045973594572, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 56 in 301 steps, with reward 20.0!\n",
      "(164, 129)\n",
      "current distance is: 10.63014581273465, and future distance is 7.280109889280518\n",
      "Just finished Episode 57 in 434 steps, with reward 10.0!\n",
      "(158, 134)\n",
      "current distance is: 12.649110640673518, and future distance is 4.47213595499958\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 58 in 269 steps, with reward 11.0!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 59 in 395 steps, with reward 13.0!\n",
      "(169, 142)\n",
      "current distance is: 17.46424919657298, and future distance is 9.219544457292887\n",
      "(169, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.46424919657298, and future distance is 9.219544457292887\n",
      "Just finished Episode 60 in 134 steps, with reward 10.0!\n",
      "(167, 135)\n",
      "current distance is: 10.295630140987, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 61 in 24 steps, with reward 17.0!\n",
      "(165, 156)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 10.44030650891055, and future distance is 20.223748416156685\n",
      "Just finished Episode 62 in 429 steps, with reward 25.0!\n",
      "(158, 132)\n",
      "current distance is: 14.560219778561036, and future distance is 5.656854249492381\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 63 in 261 steps, with reward 17.0!\n",
      "(164, 127)\n",
      "current distance is: 19.1049731745428, and future distance is 9.219544457292887\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 64 in 43 steps, with reward 3.0!\n",
      "(164, 131)\n",
      "current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 65 in 573 steps, with reward 17.0!\n",
      "(164, 128)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 66 in 106 steps, with reward 10.0!\n",
      "(171, 141)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.4928556845359, and future distance is 10.295630140987\n",
      "Just finished Episode 67 in 392 steps, with reward 22.0!\n",
      "(173, 143)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.248456731316587, and future distance is 13.038404810405298\n",
      "Just finished Episode 68 in 62 steps, with reward 16.0!\n",
      "Just finished Episode 69 in 10000 steps, with reward 30.0!\n",
      "(166, 134)\n",
      "current distance is: 14.142135623730951, and future distance is 4.47213595499958\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 70 in 37 steps, with reward 31.0!\n",
      "(162, 133)\n",
      "current distance is: 10.44030650891055, and future distance is 3.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 71 in 1732 steps, with reward 23.0!\n",
      "(169, 132)\n",
      "current distance is: 17.46424919657298, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 72 in 49 steps, with reward 15.0!\n",
      "(157, 148)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 13.0, and future distance is 13.0\n",
      "Just finished Episode 73 in 193 steps, with reward 29.0!\n",
      "(162, 126)\n",
      "current distance is: 20.0, and future distance is 10.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 74 in 59 steps, with reward 21.0!\n",
      "(167, 142)\n",
      "current distance is: 16.15549442140351, and future distance is 7.810249675906654\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 75 in 1600 steps, with reward 22.0!\n",
      "(167, 128)\n",
      "current distance is: 18.681541692269406, and future distance is 9.433981132056603\n",
      "Just finished Episode 76 in 2701 steps, with reward 8.0!\n",
      "(162, 138)\n",
      "current distance is: 10.198039027185569, and future distance is 2.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 77 in 427 steps, with reward 5.0!\n",
      "(167, 138)\n",
      "current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 78 in 17 steps, with reward 7.0!\n",
      "(163, 141)\n",
      "current distance is: 10.295630140987, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 79 in 1093 steps, with reward 8.0!\n",
      "(165, 127)\n",
      "current distance is: 19.235384061671343, and future distance is 9.486832980505138\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 80 in 1307 steps, with reward 3.0!\n",
      "(160, 143)\n",
      "current distance is: 10.63014581273465, and future distance is 7.280109889280518\n",
      "Just finished Episode 81 in 1329 steps, with reward 19.0!\n",
      "(164, 145)\n",
      "current distance is: 19.1049731745428, and future distance is 9.219544457292887\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 82 in 257 steps, with reward 7.0!\n",
      "(166, 140)\n",
      "current distance is: 14.560219778561036, and future distance is 5.656854249492381\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 83 in 608 steps, with reward 26.0!\n",
      "(168, 136)\n",
      "current distance is: 11.661903789690601, and future distance is 6.0\n",
      "Just finished Episode 84 in 314 steps, with reward 4.0!\n",
      "(163, 145)\n",
      "current distance is: 19.026297590440446, and future distance is 9.055385138137417\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 85 in 238 steps, with reward 20.0!\n",
      "(167, 129)\n",
      "current distance is: 16.55294535724685, and future distance is 8.602325267042627\n",
      "Just finished Episode 86 in 4541 steps, with reward 15.0!\n",
      "(166, 136)\n",
      "current distance is: 14.0, and future distance is 4.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 87 in 343 steps, with reward 15.0!\n",
      "(154, 134)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 88 in 1789 steps, with reward 19.0!\n",
      "(166, 132)\n",
      "current distance is: 14.560219778561036, and future distance is 5.656854249492381\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 89 in 127 steps, with reward 11.0!\n",
      "(161, 146)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.024984394500787, and future distance is 10.04987562112089\n",
      "Just finished Episode 90 in 2079 steps, with reward 13.0!\n",
      "(171, 136)\n",
      "current distance is: 19.0, and future distance is 9.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 91 in 9493 steps, with reward 19.0!\n",
      "(161, 135)\n",
      "current distance is: 11.045361017187261, and future distance is 1.4142135623730951\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 92 in 7476 steps, with reward -64.0!\n",
      "(168, 140)\n",
      "current distance is: 15.231546211727817, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 93 in 81 steps, with reward 25.0!\n",
      "(167, 137)\n",
      "current distance is: 12.083045973594572, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 94 in 2906 steps, with reward 9.0!\n",
      "(169, 137)\n",
      "current distance is: 13.038404810405298, and future distance is 7.0710678118654755\n",
      "Just finished Episode 95 in 2525 steps, with reward 10.0!\n",
      "(153, 135)\n",
      "current distance is: 12.727922061357855, and future distance is 9.055385138137417\n",
      "Just finished Episode 96 in 5266 steps, with reward 12.0!\n",
      "(158, 142)\n",
      "current distance is: 16.492422502470642, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 97 in 209 steps, with reward 17.0!\n",
      "(159, 131)\n",
      "current distance is: 15.297058540778355, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 98 in 7076 steps, with reward -22.0!\n",
      "(170, 137)\n",
      "current distance is: 18.027756377319946, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 99 in 2409 steps, with reward 25.0!\n",
      "(160, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 100 in 4211 steps, with reward 9.0!\n",
      "(165, 144)\n",
      "current distance is: 15.264337522473747, and future distance is 8.54400374531753\n",
      "Just finished Episode 101 in 1589 steps, with reward -63.0!\n",
      "(165, 145)\n",
      "current distance is: 15.811388300841896, and future distance is 9.486832980505138\n",
      "Just finished Episode 102 in 817 steps, with reward 7.0!\n",
      "Just finished Episode 103 in 10000 steps, with reward -4.0!\n",
      "Just finished Episode 104 in 10000 steps, with reward 2.0!\n",
      "Just finished Episode 105 in 10000 steps, with reward 5.0!\n",
      "(156, 142)\n",
      "current distance is: 17.08800749063506, and future distance is 8.48528137423857\n",
      "(156, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.08800749063506, and future distance is 8.48528137423857\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 106 in 638 steps, with reward 16.0!\n",
      "(166, 139)\n",
      "current distance is: 14.317821063276353, and future distance is 5.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 107 in 500 steps, with reward 18.0!\n",
      "(159, 127)\n",
      "current distance is: 19.235384061671343, and future distance is 9.486832980505138\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 108 in 553 steps, with reward 5.0!\n",
      "(168, 137)\n",
      "current distance is: 12.529964086141668, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 109 in 8682 steps, with reward 23.0!\n",
      "Just finished Episode 110 in 10000 steps, with reward 14.0!\n",
      "(156, 144)\n",
      "current distance is: 18.973665961010276, and future distance is 10.0\n",
      "Just finished Episode 111 in 1884 steps, with reward 18.0!\n",
      "(165, 131)\n",
      "current distance is: 13.92838827718412, and future distance is 5.830951894845301\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 112 in 1525 steps, with reward 4.0!\n",
      "(161, 141)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 113 in 349 steps, with reward 11.0!\n",
      "(149, 137)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.029386365926403, and future distance is 13.038404810405298\n",
      "Just finished Episode 114 in 741 steps, with reward 5.0!\n",
      "(167, 130)\n",
      "current distance is: 16.76305461424021, and future distance is 7.810249675906654\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 115 in 1019 steps, with reward 4.0!\n",
      "(171, 132)\n",
      "current distance is: 19.4164878389476, and future distance is 9.848857801796104\n",
      "Just finished Episode 116 in 191 steps, with reward 25.0!\n",
      "(153, 135)\n",
      "current distance is: 14.212670403551895, and future distance is 9.055385138137417\n",
      "Just finished Episode 117 in 2525 steps, with reward 19.0!\n",
      "Just finished Episode 118 in 10000 steps, with reward 16.0!\n",
      "(159, 134)\n",
      "current distance is: 13.152946437965905, and future distance is 3.605551275463989\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 119 in 108 steps, with reward 14.0!\n",
      "(163, 138)\n",
      "current distance is: 11.180339887498949, and future distance is 2.23606797749979\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 120 in 2694 steps, with reward 22.0!\n",
      "(163, 131)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 121 in 3333 steps, with reward 25.0!\n",
      "(158, 135)\n",
      "current distance is: 11.704699910719626, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 122 in 1604 steps, with reward 20.0!\n",
      "(169, 130)\n",
      "current distance is: 18.027756377319946, and future distance is 9.219544457292887\n",
      "Just finished Episode 123 in 1685 steps, with reward 7.0!\n",
      "(160, 127)\n",
      "current distance is: 19.1049731745428, and future distance is 9.219544457292887\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 124 in 214 steps, with reward 4.0!\n",
      "(168, 132)\n",
      "current distance is: 16.492422502470642, and future distance is 7.211102550927978\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 125 in 95 steps, with reward 9.0!\n",
      "(170, 144)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 19.697715603592208, and future distance is 11.313708498984761\n",
      "Just finished Episode 126 in 132 steps, with reward 8.0!\n",
      "(166, 135)\n",
      "current distance is: 14.035668847618199, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 127 in 1232 steps, with reward 24.0!\n",
      "(166, 148)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 22.360679774997898, and future distance is 12.649110640673518\n",
      "Just finished Episode 128 in 116 steps, with reward 10.0!\n",
      "(162, 144)\n",
      "current distance is: 12.806248474865697, and future distance is 8.0\n",
      "Just finished Episode 129 in 3560 steps, with reward 10.0!\n",
      "(165, 137)\n",
      "current distance is: 13.038404810405298, and future distance is 3.1622776601683795\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 130 in 459 steps, with reward 19.0!\n",
      "(166, 135)\n",
      "current distance is: 14.035668847618199, and future distance is 4.123105625617661\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 131 in 597 steps, with reward 21.0!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_episodes = 200\n",
    "#num_episodes = 5 \n",
    "training_loss = []\n",
    "training_reward = []\n",
    "training_steps = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    episode_loss = 0.0\n",
    "    episode_reward = 0.0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        episode_reward+= reward.item()\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        \n",
    "        step_loss = optimize_model()\n",
    "        if step_loss is not None:\n",
    "            episode_loss += step_loss.item()\n",
    "        \n",
    "        if done:\n",
    "            # episode_durations.append(t + 1)\n",
    "            # plot_durations()\n",
    "            training_steps.append(t+1)\n",
    "            \n",
    "            if episode_loss is not None:\n",
    "                training_loss.append(episode_loss)\n",
    "            \n",
    "            training_reward.append(episode_reward)\n",
    "\n",
    "            print(f\"Just finished Episode {i_episode} in {t+1} steps, with reward {episode_reward}!\")\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "# save model. \n",
    "torch.save(policy_net.state_dict(), f\"{model_type}_policy_network_gymTEEN_{num_episodes}episodes.pkl\")\n",
    "# save model. \n",
    "torch.save(target_net.state_dict(), f\"{model_type}_target_network_gymTEEN_{num_episodes}episodes.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ce102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished Episode 0 in 10000 steps!\n",
      "(151, 137)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 21.02379604162864, and future distance is 11.045361017187261\n",
      "Just finished Episode 1 in 63 steps!\n",
      "(150, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 22.80350850198276, and future distance is 13.416407864998739\n",
      "Just finished Episode 2 in 21 steps!\n",
      "(165, 143)\n",
      "current distance is: 17.26267650163207, and future distance is 7.615773105863909\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 3 in 520 steps!\n",
      "(165, 143)\n",
      "current distance is: 17.26267650163207, and future distance is 7.615773105863909\n",
      "(165, 143)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 17.26267650163207, and future distance is 7.615773105863909\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 4 in 1008 steps!\n",
      "(150, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 22.80350850198276, and future distance is 13.416407864998739\n",
      "Just finished Episode 5 in 14 steps!\n",
      "(159, 133)\n",
      "current distance is: 13.341664064126334, and future distance is 4.242640687119285\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 6 in 5770 steps!\n",
      "(156, 135)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 7 in 843 steps!\n",
      "(157, 129)\n",
      "current distance is: 17.72004514666935, and future distance is 8.602325267042627\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 8 in 659 steps!\n",
      "(168, 137)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 9 in 58 steps!\n",
      "(155, 139)\n",
      "current distance is: 17.26267650163207, and future distance is 7.615773105863909\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 10 in 143 steps!\n",
      "(164, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 11 in 90 steps!\n",
      "(161, 142)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "(161, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 12 in 98 steps!\n",
      "(154, 134)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 13 in 1602 steps!\n",
      "(166, 131)\n",
      "current distance is: 14.866068747318506, and future distance is 6.4031242374328485\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 14 in 34 steps!\n",
      "(164, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 15 in 111 steps!\n",
      "Just finished Episode 16 in 10000 steps!\n",
      "(161, 143)\n",
      "current distance is: 13.038404810405298, and future distance is 7.0710678118654755\n",
      "Just finished Episode 17 in 264 steps!\n",
      "(162, 142)\n",
      "current distance is: 16.0, and future distance is 6.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 18 in 6 steps!\n",
      "(154, 135)\n",
      "current distance is: 18.027756377319946, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 19 in 44 steps!\n",
      "(163, 146)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.024984394500787, and future distance is 10.04987562112089\n",
      "Just finished Episode 20 in 25 steps!\n",
      "(166, 140)\n",
      "current distance is: 14.560219778561036, and future distance is 5.656854249492381\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 21 in 121 steps!\n",
      "(160, 141)\n",
      "current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "(160, 141)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 22 in 499 steps!\n",
      "Just finished Episode 23 in 10000 steps!\n",
      "(163, 141)\n",
      "current distance is: 12.083045973594572, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 24 in 252 steps!\n",
      "(168, 142)\n",
      "current distance is: 17.08800749063506, and future distance is 8.48528137423857\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 25 in 13 steps!\n",
      "Just finished Episode 26 in 10000 steps!\n",
      "(155, 137)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 27 in 691 steps!\n",
      "(163, 146)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 20.024984394500787, and future distance is 10.04987562112089\n",
      "Just finished Episode 28 in 34 steps!\n",
      "(161, 129)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 29 in 550 steps!\n",
      "(154, 138)\n",
      "current distance is: 18.110770276274835, and future distance is 8.246211251235321\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 30 in 256 steps!\n",
      "(164, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 31 in 98 steps!\n",
      "(164, 138)\n",
      "current distance is: 12.165525060596439, and future distance is 2.8284271247461903\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 32 in 97 steps!\n",
      "(159, 134)\n",
      "current distance is: 12.36931687685298, and future distance is 3.605551275463989\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 33 in 4833 steps!\n",
      "(153, 133)\n",
      "current distance is: 15.811388300841896, and future distance is 9.486832980505138\n",
      "Just finished Episode 34 in 461 steps!\n",
      "(159, 145)\n",
      "current distance is: 19.235384061671343, and future distance is 9.486832980505138\n",
      "(159, 145)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 19.235384061671343, and future distance is 9.486832980505138\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 35 in 68 steps!\n",
      "(155, 137)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 36 in 3082 steps!\n",
      "(164, 159)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 13.152946437965905, and future distance is 23.08679276123039\n",
      "Just finished Episode 37 in 471 steps!\n",
      "(150, 142)\n",
      "We STOPPED USING THE OSCILLATION: current distance is: 12.649110640673518, and future distance is 13.416407864998739\n",
      "Just finished Episode 38 in 15 steps!\n",
      "Just finished Episode 39 in 10000 steps!\n",
      "(156, 135)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 40 in 1510 steps!\n",
      "(169, 137)\n",
      "current distance is: 17.029386365926403, and future distance is 7.0710678118654755\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 41 in 439 steps!\n",
      "(170, 135)\n",
      "current distance is: 18.027756377319946, and future distance is 8.06225774829855\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 42 in 99 steps!\n",
      "(156, 137)\n",
      "current distance is: 16.0312195418814, and future distance is 6.082762530298219\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 43 in 5197 steps!\n",
      "(157, 135)\n",
      "current distance is: 15.033296378372908, and future distance is 5.0990195135927845\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 44 in 346 steps!\n",
      "(160, 131)\n",
      "current distance is: 15.132745950421556, and future distance is 5.385164807134504\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 45 in 169 steps!\n",
      "(156, 129)\n",
      "current distance is: 18.027756377319946, and future distance is 9.219544457292887\n",
      "Just finished Episode 46 in 557 steps!\n",
      "(171, 139)\n",
      "current distance is: 11.40175425099138, and future distance is 9.486832980505138\n",
      "Just finished Episode 47 in 553 steps!\n",
      "(171, 135)\n",
      "current distance is: 19.026297590440446, and future distance is 9.055385138137417\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 48 in 215 steps!\n",
      "(155, 136)\n",
      "current distance is: 17.0, and future distance is 7.0\n",
      "the stepsize has decreased and is now 5\n",
      "Just finished Episode 49 in 4719 steps!\n",
      "Average Testing Steps for 100 episodes is 1734.36\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 100\n",
    "total_test_steps = 0\n",
    "for i_episode in range(test_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            total_test_steps +=t+1\n",
    "\n",
    "            print(f\"Just finished Episode {i_episode} in {t+1} steps!\")\n",
    "            break\n",
    "\n",
    "print(f\"Average Testing Steps for 100 episodes is {total_test_steps / test_episodes}\")\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Testing Steps for 50 episodes is 1734.36\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEWCAYAAADCeVhIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABhkUlEQVR4nO29eXwb5bX//37kRV4jx87mbJ5sJIEQAoQdyn4LVdm6pNAWKBdKaemlC+2t4NfClJZ7de+3lMJtaQstS9lTSikgypayEyAJhASSACGZJF7ibLa8L5Lm98fM2LKtZWRb0sh+3q+XXpJmfWakmTPnPOf5HKHrOhKJRCKROAlXthsgkUgkEslgpHGSSCQSieOQxkkikUgkjkMaJ4lEIpE4DmmcJBKJROI4pHGSSCQSieOQxkliGyHEN4QQr2doXy8LIa7IxL7GA0IIRQihCyHys90WOwgh/iCE+NkobzNj/1/JyJHGySEIITQhRKcQok0IsVsIca8Qoizb7XIiQogKIcTd5nlqFUJ8LIT4SdR8XQgxPwvtGtF+hRCFQogbhBAfCSHahRB1Qoh/CiH+bTTbmSnMB4wu8z9tvZ6ys66u61fpuv6LdLdR4lykcXIW5+i6XgYsAw4HrstWQxz+hH0rUAYsBjzAucCnWW3R6PAYcB5wCTARmAPcBniz2agR8l1d18uiXudku0GS3EAaJwei6/pu4DkMIwWAEOJYIcSbQohmIcT7QohTzOmnCiE2Ri33ohDinajvrwshzjc/+4QQn5rexiYhxAVRy31DCPGGEOJWIcQBQBVCVAkhnhRCtJjbnJeo3UKIv5reTFAI8aoQ4pCoefcKIX4nhAiY+39bCDEvav6ZQogt5rq/BUSCXR0FPKTrepOu6xFd17fouv6YuZ1XzWXeN5/Uv2JO/7wQYr15/t4UQiyN2rcmhLjOPCdNQoh7hBBF5rxJQoinzfUOCCFeE0IMuW4S7PebQoit5rpPCiGmxzl3ZwBnAufpuv62rus95utZXde/F7XcYtMjaRZCfCiEODdqnlcI8Z75e+0SQqgJzmH0vn1CiMcGTbtNCHG7+fkbQoht5u+2XQjxNTvbTbLPU4QQtUKI64UQ+8zf4GtR8+8VQvzS/Bz3N0hyPhL+f4UQi4QQL5jb/EgIsSJq3ufM/0OrMDzYH430mCUpouu6fDngBWjAGebnmcBG4Dbz+wxgP/A5jAeKM83vk4EioBOYBOQDu4F6oBwoNudVmdv5MjDd3MZXgHag2pz3DSAE/Ie5nWLgEWAlUAosAeqA1xMcw7+b+3UDvwHWR827FzgAHG1u/0HgEXPeJKAF+BJQAPzAbMsVcfbzJ+BD4DJgQYz5OjA/6vsRwB7gGCAPuNQ83+6oc/8BMAuoBN4AfmnO+2/gD2a7CoCTABGnXYP3exqwz9y/G/g/4NU46/qBl5P8RwqArcD1QKG5/VZgoTn/FOBQ8/ddCjQC55vzFLN9+TG2WwN0ABPM73lAA3Cs+du3RO2jGjjE5n/65QS/4Snmb/xr89ycjPF/tPZzb7LfwMb5iPv/NaftMv9D+eZvtM86NvP4TzI/TwSOyPY9Yry9st4A+TJ/COMG2WZeXDqwCqgw5/0EuH/Q8s8Bl5qfXwO+YN5MnjcvyLOAU4ENCfa5HuNJHQzjtDNqXh7QCyyKmvZfJDBOg7ZdYR6Hx/x+L/CnqPmfA7aYny8B3oqaJ4DaBDe2YvOGtM5s41bg7Kj5g43E74FfDNrGR8DJUef+qkFt+9T8fBPwj+jtJTjmwfv9M/C/Ud/LzPYqMdb9E6axNr9XAs1AEOgyp52E8fDhilruYUCN057fALeanxXiGCdz/uvAJebnM6OOv9RsxxeB4hT/0y9jGL3mqNcvzHmnYBin0qjlVwI/i/q/WMYp5m+Q6HyQ5P+L8XD22qDt/RG40fy8E/gWpsGWr8y/ZFjPWZyv63o5xoW7CMOjAOPJ9stm6KJZCNEMnIjxFAvwirnOZ8zPL2M8iZ5sfgdACHFJVGirGeNp0toHGE+SFpMxniijp+2I13AhRJ4Qwm+GDVswbvgM2v7uqM8dGDdrMLy5vv3oxt0her8D0HW9U9f1/9J1/UigCuOm9lchRGWcVWqAawedv1nmfi0GH6c17/9hGL/nzdCWL167YjCdqHOm63obhsc7I8ay++n/PdF1/YCu6xXAkRiehbW9XbquRwa1dQaAEOIYIcRLQoi9QoggcBUDz38iHgIuMj9/1fyOruvtGDfyq4AGMyy7yOY2Aa7Rdb0i6hWdgddkbj/6WGKFPeP9BonOR7L/bw1wzKD/xNeAaeb8L2I8pOwQQrwihDguhWOWjALSODkQXddfwXhy/JU5aReG5xR9kZfquu435w82Tq8wyDgJIWqAu4DvYoT5KjBCWdF9O9ES9XsxnmxnRU2bnaDZX8XozD8DI0lBMacn6juyaIjejxBCDNpvXHRdb8F4Ii7FSCCIxS7g5kHnr0TX9Yejlhl8nPXm9lt1Xb9W1/W5wDnAD4UQp9tpm7mNmqjjKsUwpnUxll0FHCWEmJlke7MG9XnNjtreQ8CTwCxd1z0YoTA75x/gr8Ap5v4vMLcFgK7rz+m6fiaG8dyC8T8aDSaa58Si77xHk+A3SHQ+kv1/dwGvDPpPlOm6/m1zn2t0XT8PmAI8gfEAJMkg0jg5l98AZwohlgEPAOcIIT5reihFZoeydSN7E1iI0Z/zjq7rH2I+GQJWR30phvHZCyCEuAzDc4qJruth4HGMxIgSIcTBGH018SgHujE8gBIMg2GXAHCIEOILwsgSvIb+J9ghCCF+JoQ4Ship10XA9zBCRh+ZizQCc6NWuQu4yvQshBCi1EweKI9a5mohxEzT+7oeeNTc1+eFEPNNg9kChM1XLAbv9yHgMiHEMiGEG+OcvK3rujZ4RV3XnwdeAp4w21kohCjACNVavI3RL/OfQogCYSTFnIPRtwLGb3BA1/UuIcTRGA8MttB1fS+Gx30PsF3X9c3m8U8VQpxrGpFujNBzvOMfDj83j/Uk4PMYRnIACX6DuOfDxv/3aeAgIcTF5roF5n9qsdmerwkhPLqu90btU5JBpHFyKObN4i8YMfhdGF7J9RjGZRfwY8zfzwyNvAt8qOt6j7mJ1cAOXdf3mMtsAm4xpzdidJy/kaQZ38UIve3G8OTuSbDsXzDCJnXAJuCtFI51H0ayhh/DuC1I0jbdbMs+jKfnMwGvGTYDo8/hPjNcs0LX9bXAN4HfAk0YIaJvDNrmQxj9ddvM1y/N6QuAFzFuyquBO3RdfzlOuwbvdxXwM+BvGN7hPODCBMf1BYyb5gMYxnY7RqjpLADztz0XONs89jsw+om2mOt/B7hJCNEK3EDqT/sPYXi+D0VNcwHXYpznAxje+HcAhBAnCSHaBm9kEL8VA8c5rYuatxvj96jHSJC5KupYoon5G9g4H3H/v7qutwL/hvF71JvL/A/9IdSLAc0MUV8FfD3JcUpGGWGE9yWS8YsQQsNIvngx220ZL5hezgO6ricKY0rGMdJzkkgkEonjkMZJIpFIJI5DhvUkEolE4jik5ySRSCQSx+Fkcc+kTJo0SVcUJdvNkEgkkpxi3bp1+3Rdn5ztdiQip42ToiisXbs2282QSCSSnEIIEVftBQDVU4QxRtKNYSceQw3eiOpRMYZl7DWXvB41+Ew62pjTxkkikUgkaaEbOA012IbqKQBeR/X805x3K2rwVwnWHRWkcZJIJBLJQNSgjjHoGfrV4DOaPSeNk0QikYwzrj2ucBKqJ7pP5E7U4J0DFlI9eRjK//OB36EG30b1nA18F9VzCbAWuBY12JSONuZ0Kvny5ct12eckkUgkqSGEWKfr+nJbC6ueCuDvGLXe9mJIRenAL4Bq1OC/p6ONMpVcIpFIJPFRg80YosBnoQYbUYNh1GAEQ1D56HTtVhqnXGLDSrh1CagVxvsGqeIvkUjSgOqZbHpMoHqKMQSBt6B6qqOWugCj7E5akH1OucKGlfDUNdDbaXwP7jK+Ayxdkb12SSSSsUg1cJ/Z7+QCVqIGn0b13I/qWYYR1tMwqgWnBdnnlCvcusQwSIPxzIIfpO3hRSJJSGNLF+t3NfPZQ+KW35I4kJT6nLKEDOvlCsHa1KZLJBng4Xd28u0H1tEbjiRfWCJJAWmccgVPnLI38aZLJBmgpTNERIf27lC2myIZY0jjlCucfgMUFA+cVlBsTJdIsoRllFq7pHGSjC7SOOUKS1fAObcbfUwI4/2c22UyhCSrtPcYRqlNek6SUUZm6+USS1dIYyRxFJbnJI2TZLSRnpNEIhk27T1hANpkWE8yykjjJJFIho30nCTpQhoniUQybDosz0kaJ8koI42TRCIZNpZRkmE9yWgjjZNEIhk2fank0nOSjDLSOEkkkmERieh9YT05CFcy2kjjJJFIhkVHb7jvswzrSUabtI1zUnyBIuBVwG3u5zHN771R8QVU4JsYRasArtf83mfMda4DLgfCwDWa3/tcutonkUhGRkeUtyQTIiSjTToH4XYDp2l+b5viCxQAryu+wD/Nebdqfu+vohdWfIGDgQuBQ4DpwIuKL3CQ5veGkUgkjiPaIMk+J8lokzbjpPm9OtBmfi0wX4nqc5wHPKL5vd3AdsUX2IpRZXF1utookUiGj9XfBLLPSTL6pFW+SPEF8oB1wHzgd5rf+7biC5wNfFfxBS4B1gLXan5vEzADeCtq9Vpz2uBtXglcCeBq70ln8yUSSQIsz2lCUb7sc5KMOmlNiND83rDm9y4DZgJHK77AEuD3wDxgGdAA3GIuLmJsYoinpfm9d2p+73LN711eWVqYlnZLJJLkWN7S1AlFss9JMupkJFtP83ubgZeBszS/t9E0WhHgLozQHRie0qyo1WYC9Zlon0QiSR1LV2/qhCJau3qz3BrJWCNtxknxBSYrvkCF+bkYOAPYovgC1VGLXQBYNcafBC5UfAG34gvMARYA76SrfRKJZGREe07tPWF0PVGXskSSGun0nKqBlxRfYAOwBnhB83ufBv5X8QU2mtNPBX4AoPm9HwIrgU3As8DVMlNPInEu/cbJTTii09UrS7VLRo90ZuttAA6PMf3iBOvcDNycrjZJJJLRo73beHacUu4GoLW7l+LCvGw2STKGkAoREolkWHT0hCgqcFFRYiQmyYw9yWgijZNEIhkWbd0hSgvzKXMbARjLk5JIRgNZpl0ikQyLjp4wpe58Sk3j1NotM/bGDKpniPwcavBGVE8l8CigABqwAjXYlI4mSM8pBntbu/nTa9tk9pFEkoC27hAlhXmUFxnGSYb1xhTdwGmowcMwxqSeheo5FvABq1CDC4BV5ve0II1TDJ7eUM8vA5tpCHZluykSiWNp7w5R5u4P68mBuGMINaijBmPJz50H3GdOvw84P11NkGG9GDR3GOEJebFJJPFp7wlTUVxAWZHV5ySvl1zh2uMKJ6F61kZNuhM1eOeAhVTPAPk51ODbqJ6pqMEGY36wAdUzJV1tlMYpBi1d0jhJJMlo7w4xo6Koz3OSyuS5wy2re/b96s3u5QkXUoNhYBmqpwL4O6pnSSbaZiHDejEIdprGScbQJZK4dJjZeu58F/kuIa+XsYoabMaUnwMaUT2Gyo/xviddu5XGKQYtpnGSYQqJJD5t3SFK3fkIISgrypeRhrGE6plsekygevrk5zBk5i41l7oU+Ee6miCNUwz6PCd5sUkkMdF13UwlNxQhytzSOI0xqoGXUD198nOowacBP3AmqucT4Ezze1qQfU4xCErPSSJJSHcoQiiiU1Jo3ELK3LKm05hCDcaUn0MN7gdOz0QTpOcUA+k5SSSJsR7crGQI6TlJRhtpnGLQb5ykHItEEgurRHuJKfQq+5wko400ToPoDoX7pP9lWE8iiU1bLM9JhvUko4g0ToOwvCaQxkkiiUdHj3FtWLp65dJzkowy0jgNoiXKOMlBhRJJbKyQt5WtV1oojZNkdJHGaRDBzv4LTHpOEklsOroHek5lRfl09IQJR6RYsmR0SFsqueILDJFc1/zeGxVfYIjkuub3NpnrXAdcDoSBazS/97l0tS8elufkKS6QxkkiiYPlJZVGpZJb0z3FBVlrl2TskE7PqRs4TfN7+yTXFV+gT3Jd83sHSK4rvsDBwIXAIRgyGXcovkDGaz5bfU7TK4plmEIiiUN799A+p+jpEslISZvnpPm9OhBPcv0Uc/p9GJpNPzGnP6L5vd3AdsUX2AocDaxOVxtjYRmnGRVFfFDXksldSyQ5Q/ugVPJSWTZDMsqktc9J8QXyFF9gPYY44Aua3/s2MFXzexsAzHdLcn0GsCtq9VpzWkaxjFO1R3pOEkk82rtD5LsE7nzjFtKnTC7TySWjRFrlizS/NwwsU3yBCuDvii+QSHJdxJg2pHdV8QWuBK4EcLX3jEYzBxDs7KWkMI+JJQW094TQdR0hYjVNIhm/WCXarWujrxpuKg90G1bCqpsgWAuemXD6DbB0RTqaK8lBMpKtp/m9zURJriu+QDWA+W5JrtcCs6JWmwnUx9jWnZrfu1zze5dXlhaOeluDnb1MKCqg1J2PrvePhJdIJP20dYcoLezvEi5zG0kQtvucNqyEp66B4C5AN96fusaYLpGQRuOk+AKTTY8JxRewI7n+JHCh4gu4FV9gDrAAeCdd7YtHsLMXT3FBXwxddvBKJEPp6An1XSPQP97JtkrEqpugt3PgtN5OY7pEQno9p2rgJcUX6JNc1/zePsl1xRcYILmu+b0fAiuBTcCzwNVmWDCjWMZJVveUSOLT1h2mJMo4lZuek+3rJVib2nTJuCOd2XoxJdc1vzeu5Lrm994M3JyuNtmhpbOXmRNL+oyT9JwkkqG0d4coc/eH9VL2nDwzzZBejOkSCVIhYgiDw3oyY08iGUp7d6ivlhNAfp6L4oI82ntsXi+n3wAFxQOnFRQb0yUSxqtx2rASbl0CaoXxHtUJ2zIorNeeatmMBNuWSMYK7T2hvmvEotSdPzCVPNG1sHQFnHM7eGYBwng/53aZrSfpY/xVwrWyhKzOWCtLCOg95Eu094RNz8kIU6QU1kuwbXnRScYSHd3hvgG4FgOUye1cC0tXyOtCEpfx5zklyBLq19XLH15ChMxAkowT2rqHek5GTSdT1V9eC5IRMv6MU4IsIUsdwlNSQNlwtMJkBpJkHBAKR+gORQakkoNhnPrC4PJakIyQ8Wec4mUDeWb2G6fiAooL8nCJFI1Tgm1LJGOFwbp6FmVF+f2RBnktSEbI+DNOCbKEoo2TECL1AmoyA0kyDrCq4MYM63WbYT15LUhGyPhLiLA6YGNoegXX1wEwocgYUFjqzrc/biPJtiWSsYIVTSiJ2edkXi/yWshtVM8s4C/ANCAC3IkavA3VowLfBPaaS16PGnwmHU0Yf8YJ4mYJRRcaBCNMYXvcRpJtS8Yw40zA1CrRHj0IF8zrJXrohbwWcpkQcC1q8F1UTzmwDtXzgjnvVtTgr9LdgPFpnOJghfUmFEd5TqmOc5KML8bh8AGrRHv0IFwwPKeecITuUBh3fsbrhEpGEzXYADSYn1tRPZvJcAmj8dfnlIBgZy/ufBdFBcaFVebOk/JFksSMw5Rpqx82Vp8TpCBhJMkNVI+CIUX3tjnlu6ieDaieu1E9E9O1W2mcomjpDPWF9AAjIUJeaJJEjMOU6Y542XpS8itnuPa4wkmonrVRrytjLqh6yoC/Ad9HDbYAvwfmAcswPKtb0tVGGdaLwtLVsygrSjFbTzL+GIcCpnE9p+EUHJRkhVtW9+z71ZvdyxMupHoKMAzTg6jBx41pwcao+XcBT6erjdJzimKIcXIPIyFCMr4YhynTVir54EG45TKsN3ZQPQL4M7AZNfjrqOnVUUtdAHyQriZIzymKYGcv1Z6ivu+l7nzZ55QpcjXjbRymTFtJQsUFA8N6Usk/Q2TmWjkBuBjYiOpZb067HrgI1bMM0AEN+NZo79hCGqcogp29LJpW3ve9zJ1Pb1iX2UfpJtcz3sZZynS7WaLd5RIDpsuwXgbI1LWiBl8HRIw5ycc0qZ4fJtn2rxPON5FhvShaOnv70sgBSgtTLKAmGR7jMOMtl+noCQ0ZgAv9Yb1Web2kj9y4VsrN13Lg2xgp6DOAq4CD7W5Eek4m4YhOa3doUEKE8bm9O0xVWbZaNg4YhxlvuUxbd3hIMgQwPLFkSWrkwrWiBn9uvHueB45ADbaa31Xgr3Y3kzbjpPgCQ+QvNL/3NsUXUBkkf6H5vc+Y61wHXA6EgWs0v/e5dLVvMC2DBuBC/wh4GaZIM+Mw4y2X6egODUkjB/rEkuX1kkZy61qZDfREfe8BFLsrp9NzCgHXan7vu4ovUA6sU3yBPvkLze8dIH+h+AIHAxcChwDTgRcVX+Agze/NiERDcJB0EfR38MqMvTRz+g0D4+gw5jPecpm27tCQTD3AEEseXA1XMrrk1rVyP/AOqufvGAkUFwD32V05bX1Omt/boPm975qfW4Fk8hfnAY9ofm+35vduB7YCR6erfYNJZJxkn1OakSW7c4qOnthhPTD6naTnlEZy5VoxUtH/AlwGNAHNwGWowf+2u4mM9DkpvoBCv/zFCcB3FV/gEmAthnfVhGG43oparZYYxkzxBa4ErgRwtfcMnj1sWrqGGqdymRqbOcZZxlsu094doqaqJOY8Q/xVXi9pJReuFTWoo3qeQA0eCbw7nE2kPVtP8QX65C80vzeR/EWstEV98ATN771T83uXa37v8srSwlFrZ8KwnrzYJJI+YpVotyiTnpOkn7dQPUcNd+W0ek6KL9Anf6H5vY8DaH5vY9T8aPmLWmBW1Oozgfp0ti+ahGE9ebFJJH109ISHKJJbyD4nSRSnAt9C9ewA2jEcEB01uNTOyunM1uuTv9D83l9HTa/W/N4G82u0/MWTwEOKL/BrjISIBcA76WrfYGIaJzMjqV2WzZBIANB1nfae0JBaThblRfk0BLsy3CqJQzl7JCun03Pqk79QfIH15rTrgYsUX2AZg+QvNL/3Q8UXWAlswsj0uzpTmXpgGKfCPBdFBf2Rznzze1/paYlknNPZG0bXh1bBtSiTkl8SCzW4w3j3TAGKEi88lLQZJ83vTVn+QvN7bwZuTlebEmGpQwgxSJLFXSALDkokJlaIO1YqOZjXiwzrSQBUz7kYOQXTgT1ADUbW9iF2Vk+aEKH4AvMUX8Btfj5F8QWuUXyBimE32KEYiuQxRr3LgoMSSR8d5oNaaYxBuGBcL209ISKRIblMkvHHL4BjgY9Rg3OA04E37K5sJ1vvb0BY8QXmY/QhzQEeGkZDHc3gchkWUplcIuknqedUlI+uQ0evjDZI6EUN7gdcqB4XavAljCxtW9gxThHN7w1hJC/8RvN7fwBUJ1kn5wgOEn21KHXn0yqNk0QC9FfBjZ9KbulRymtGQrNZSfdV4EFUz20Y+QS2sGOcehVf4CLgUvrTvofexXOceJ5TufScJJI+rGshlrYe9Iu/ynRyCYbqTwfwA+BZ4FPgHLsr20mIuAxD6vxmze/drvgCc4AHhtFQR9PSGZJhPYkkCfFKtFtIsWRJFF8BXkMNfkIKmnoWSY2T5vduUnyBHwGLFF/gUOAjze/1p95O5xKJ6LR0xe9zktl6EomBVaI9fiq5cQ3JjD0JhgL511E9CoZU3WsYxmq9nZXtZOt5Mdyx24HfAlsVX2BEg6ucRmt3CF0npnEqc+eNn3FOG1bCrUtArTDeN6zMdoskDsN6UCuLoxBRJlVVJBZq8AbU4GkYqeOvAz8G1tld3U5Y7xbgVM3v3QpGajkQAP6ZemudSaxaThal7ny6eiOEwhHy88Zw4eBcL5UuyQgdVp9TAoUIkMZJAqien2KIMZQB7wE/wvCebGHnbrvHMkwm2zAGVI0ZYkkXWZT11XQa46G93Cj/LMkybT0hCvNdFMR5UOsvMzNOog2SRHwBqAJeBB4HnkQNNiRepR87ntOHii/wDLASQ3Loy8AaxRf4AoAl6JrL2DJO3bETJsYMuVD+WZJ1OuKUaLcolQkREgs1eASqpxw4ETgTuAvV04gaPNHO6naMUxHQCJxsft8LVGKkBOoYFjGnSWScxk3ZjNwq/yzJEu1xSrRbuPPzKMx3ySQiCaieJcBJGLZjObCLFMJ6drL1Lht243IEO57TmB+Im1vlnyVZIlEtJwujGq4M60n4H4wBuLcDa1CDKf0pkhonxRc4CKNA4FTN712i+AJLgXM1v/eXw2mtE0lonIrGiedkJT2suskI5XlmGoZJJkNIojBqOcX3nMAcfiFTyXMb1TMLo8z6NCAC3IkavA3VUwk8ipEmrgErUINNsbcR9KJ6ioHZqRomsJcQcRdwHdALoPm9G4ALU92Rkwl29pLnEjEvutLCcWKcwDBEP/gA1GbjPZcMU66mwTu53THa1tYdiqurZyGr4Y4JQsC1qMHFGOKtV6N6DgZ8wCrU4AJglfk9NqrnHGA9hjoEqJ5lqJ4n7TbAjnEq0fzewUX/xtQ/r8WULhpcLgOix23IGLpjsdLgg7sAvT8N3kk3+lg4ud1x2nZM24t9D2zxKCuS1XBzHjXYgBp81/zcilHqYgaGJJGl9nAfcH6irQBHA83mdtZjeFy2sGOc9pljm3QAxRf4EmA7HTAXiKerB1HZRzI11rnkahq8k9sdp22Xdd6f1HMqd+fT3iON05jBUHg4HHgbmNqXDm68T0mwZgg1GBzubu1k610N3IkhX1QHbAe+NtwdOpF4iuQQla031sc55TK5mgbv5HbHacMU9vU9sMWjrCifT/dK4+Rkrj2ucBKqZ23UpDtRg3cOWdBQFf8b8H3UYAuqJ5XdfIDq+SqQh+pZAFwDvGl3ZTvGSdf83jMUX6AUcGl+b6sp/poQxRcY0qGm+b23Kb7AkA41ze9tMte5DrgcCAPXaH7vc3YPZCS0dPbiKSmMOc+d76IgT8gYupPJ1TR4J7c7Ttsa9KqknlOp7HNyPLes7tn3qze7lydcSPUUYBimB1GD1pChRlRPtRH281STWJDhP4D/D+gGHsboe/qF3TbaLTaI5ve2a35vqzntMRvrhYBrNb+3r0NN8QX6OtQ0v3dAh5o570IMHaazgDsUXyDxI9ookSisJ4SQyuRO5/QbjLT3aHIhDd7J7Y7RNr2gmP/pXWErlVz2OeU4qkdgFJfdjBr8ddScJzHKJ2G+/yP+NoIdqMH/DzV4FGpwOUY1i9/abULcf5niCyzCMBQeSw3CZALGwNyEaH5vA2bflOltRXeonWIudh/wMvATc/ojmt/bDWxXfIGtGJ1pq+0ezHCJV6LdorRQpsY6mlxNg7fT7g0rs3NcMdrWfuL1PPk3DzcmSSUvc+fTHYrQG47ElTmSOJ4TgIuBjaie9ea06wE/sBLVczmwE0MxaCCqZynwK2A68HcMg3QHcAyGVqstEj0CLQQ+D1QwsEBUK/BNuzsAUHwBhagONdNwofm9DYovYHWozQDeilqt1pyWVnRdp6UrsTSRTI3NAZaucL4xikWidmdbjHdQ25oOdAAvJU8ljxobWBEnXC5xOGrwdWBo+rLB6UnWvgtjbOxqjCjYu8BDwNdQg112mxD3X6b5vf8A/qH4Asdpfu+wvRfFF+jrUNP83hbFF4i3aKwTocfY3pXAlQCu9p7hNquPtu4Q4Yie2DgVyewjSRZIlM2XBUNslWhPlkpuGa/WLmmcxilu1OC95uePUD0/AnyowZSyyhKF9b4JvKz5vasVX8CKP34R2AF8Q/N73022ccUX6OtQixKIbVR8gWrTa4ruUKsFZkWtPhOoH7xNze+9EyN7kOUv3jjEeKVKInUIi1J3ft9yEknGcFg2nxU9SJatVy5rOo13ilA9h9PvcLQBS81+LPrGTyUh0SPQ94B7zc8XAYcBczHCc7dhCPrFJcqgbdb83lgdan4Gdqg9CTyk+AK/xohVLgAGD/4ddewYpzJ3HvXNnXHnSyRpwWHZfFYV3FTCepJxSQMQfc/fHfVdB06zs5FE/7KQ5vda7sLngb9ofu9+4EXFF/hfG9vu61BTfIH15rS+DjXFFxjQoab5vR8qvsBKYBNGpt/Vmt+b9sFFLZ3GBTShKIHnJBMiJNnAYWK8lrFJqhAxXsSSJbFRg6eOxmYS/csiZtitCaMD7OaoecWxV+lH83tT7lDT/N6bB+0n7QQTVMG1kKnkkqzgsGw+S8Ir6SDcvoKD8pqRDJ9ExukGYC2QBzyp+b0fAii+wMkY1XDHBC02wnrlZkKErusx9fckkrThoGy+VMN6ss9JMhLiDkLQ/N6ngRpgseb3RqeOrwW+ku6GZYq+PqeSxJ5TRIfOXilhJHEQGdbms4xNskG4ZeOlQKckrST8l2l+bwgjrBc9rT2tLcowwc5eXALKEsTRS6PCFCVJ4u0SScbIcDZfR3cYlzAkvRJh9UlJlYhxjpGd9zVgLmrwJlTPbGAaatBWotu4H75tib66XPHDdWWWMrl8EpQ4iXhZe2nK5rNqOSULbbtcgtLCPHm9SO4AjsPI9gZDwOF3dleWximBrp5FmduY3y5rOkmcRIa1+Tp6Qkkz9SzKimSGq4RjUINXA4YqhFEx1/ao7ESDcI9ItKKdQbi5gB3jVCo9J4kTybCmYHt3OGmmnkWZO582qaoy3ulF9eRhKf2onskYFSpskegxKJFAn+2BVE7HnuckO3iTki2B0vFOBjUF23uSl2i3KCsqkJ6T5HYM4dcpqJ6bgS8BP7W7ciJtvVEZSOV0Wjp7mTEx8bCtUinHkphsC5RKMkJ7dwphPbfscxr3qMEHUT3rMMa1CuB81OBmu6vb+qcpvsAS4GCiSmVofu9fUmyqI2npsu85yYstDg4TKJWkh7buMDMq7HUZlLnz2dfakeYWSRyJ6qmM+rYHo9Bg/zw1eMDOZpIaJ8UXuBGj/tLBwDPA2cDrGFVucxpd141svQTSRSDDeklxmECpJD109IRS6HMqkA9z45d1GF0/ApiNMRxJYJRf2gkkraQO9rL1voThlu3W/N7LMARg3am313l09obpDSculwFQUpiHENI4xSXDKc2S7NDebb/PqbxI1kAbt6jBOajBucBzwDmowUmowSoMjdbHE6/cjx3j1Kn5vREgpPgCEzDctLnDabPTsKNIDmap9sJ8KWQZDyeXG5eMGu3dYUqTVMG1sAp06vqIq9pIcpejUIPP9H1Tg/8ETra7sp3HoLWKL1CBUd1wHUZtjrSXssgEdo0TGOnk0nOKQ66WSbcYy5mGo3Rs4YhOZ2/YtudU6s4nHNHp6o1QbNOgScYc+1A9PwUewAjzfR3Yb3flpP80ze/9jvnxD4ov8CwwQfN7NwynpU4j2GHfOJW58+Ug3ETkapn0sZxpOIrH1if6msIgXDCSiKRxGrdcBNyIkU4O8Cr9ahFJSRrWU3yBVdZnze/VNL93Q/S0XCYVz8kKU0jGGBkWT80oo3hs7X3lMmz2OckMV4kaPIAa/B5GKO8k1OD37GbqQWKFiCKgBJik+AIT6a/NNAGjUm3Ok1pYTxqnMclYzjQcxWOzW6LdQtZ0kqB6DsXI6q40v+8DLkUNfmBn9USPQd8Cvo9hiKKlilpIQbzPyaRqnA60y3EbYw6HlUIfVUbx2FIN65X2VcPtTbKkZAzzR+CHqMGXAFA9pwB3AsfbWTmRQsRtwG2KL/Afmt/7fyNvp/No6exFCCPtNRnl0nMamzisFPqoMorH1u852U8lh/HrOem6zvpdzSybVTGeC5SW9hkmADX4Mqqn1O7Kdv5pf1R8gWuAz5jfXwb+qPm9CR+JFF/gboy89j2a37vEnKYC3wT2motdr/m9z5jzrgMuB8LANZrf+5zdgxguLV0hyt35CctlWOREqfaxnHWWLnI90zARo3hsHTZLtFv0DVwfj+KvG1bS85zKYW11dJdOp+isn6d2zp1wHauevvs3anCJOU1l0P17QKr4ULahen4G3G9+/zqw3W4T7BinO4AC8x3gYuD3wBVJ1rsX+C1DlSRu1fzeX0VPUHyBg4ELgUMwwogvKr7AQZrfm9b0uGBnb8IKuNGUOj1bbyxnnaWbXM00tMMoHVu7zRLtFmXj1XMyr0N3bycIKOqoT+06dM51fC9x7t+owV8NXTwm/w78HGPgrQBeAS6z24C42XqKL2D9C4/S/N5LNb/3X+brMuCoZBvW/N5XAbuZGecBj2h+b7fm924HtgJH21x32NiRLrIoc+fRE47QHXKogRrLWWeSrNOXrWdb+NXqcxpnxmmk16FTrmM1mMr9O942mlCD16AGjwCWAzeYNZ1skeif9g5wBBBWfIF5mt/7KYDiC8zFCL0Nl+8qvsAlwFrgWs3vbQJmAG9FLVNrThuC4gtcCVwJ4GrvGUEz7JXLsCjt09cL48534LiNsZx1NkqEIzp5NkK4kqG0p5it5853ke8S489zGul1mKHr+NrjCiehetZGTboTNXinjVW/i+rpu38nNDaq5yHgKgx7sQ7woHp+jRr8f3bamGick3UV/wh4SfEFXlZ8gZeBfwHX2tl4DH4PzAOWAQ3014yKdceIqXui+b13an7vcs3vXV5ZaruoYkxSMU6OF3+V+nYJeWvbfg5Vn0Pb157tpuQkVkJEiU3PSQhBWVEO9NOONiO9DjN0Hd+yumcfanB51MuOYYp3/47HwajBFuB8DNHw2RjdQrZIZJwmK77AD82G/BHDKD2FIWN0uN0dRKP5vY2a3xs2tfruoj90VwvMilp0JlA/nH2kwnCMk2Mz9qS+XUI+qAvS0RPm8XelJzkcOnpCFBfkpeR5lrnHoR5ljOuwW7jtX4en30CPGKSr7ZTrWA02ogbDqMHB9+94FKB6CjCM0z9Qg73EcTpikcg45QFlQDlG+E+Y3/PNaSmj+ALVUV8vAKzBWE8CFyq+gFvxBeYAC8iAft9wwnqONU5LV8A5t4NnFiCM93NuH7sd/SlS22TE8f++vk6KkQ6Dtm77unoWZe788RfWM6/DeiahI2gumMr14W/StfiLtlaPLPkyv3Bdxb68KUR0QYt7mnOuY9UT7/4djz8CGlAKvIrqqcEYJ2uLRP+2Bs3vHXYvnOILPIxRB2qS4gvUYmgsnaL4AsswrKeGMdAXze/9UPEFVgKbgBBwdboz9bp6w/SEIkwYK8YJxnbW2QipbzaM064Dnby7s4kjayqTrCGJJpVaThbJJL90Xec/Hn6PY+ZWcfGxNSNtomNoX/gFju8qxXf2IhZOK+dv96zh3O0HOPmgyUnX/aA+yP3tx3D4iiu55fmPWa5M5LalwwpUjQzV03f/RvX03b9RPcsYdP+Ov43g7Ril2i12oHpsV1hPZJxG1HOs+b2xBP7+nGD5m4GbR7LPVEhFHQL6BxWOuxj6GKE+2Mnymol8UB/k7+/VSeOUIqmUaLcoK8qnKUHS0obaIE9vaGBXU+eYMk4NwS4Aqj1FHDe3Cne+i1c+2mvLOL2wqZE8l+DUhVN4Yn09W/e0pbu5sVGDKd2/B67r+Tpq8AFUzw/jLPFrO5tJFNY73VZDcpRUjVOp0xMiJAmpb+7ioGnlnHnwNJ7e0EBPKJLtJuUU7d3hYXlOifqcHn5nJwAf1gX75JHGArtN4zRtQhFFBXkcM7eKlz/eY2vdFzY1srxmIhNLC5k/uYxP97YRieRcGNpSgSiP87JFIvmikeW4O5yWFI1TmfnU2DreYuhjgM6eMAfae5hRUczi6nKeer+eVz7ey5kHT81203KG9p4QqWbHlhfF73Nq6w7x5Pv1zK4sYeeBDtbvaub4eZNGo6lZpz5ohJCnVxiJEaccNJmbnt7ErgMdzKosibvergMdbNndyk+9iwGYN6WUrt4I9cFOZk6Mv57jUIN/NN9/PpLN2KmEOyZJ3XMynhodrRIhiUn/zaKIkxZMprK0kCfeq8tyq/ppau/hv57Z7NwB3hjGJNWwXmlh/D6nJ9fX09ET5hfnL0EIWKvZHpvpeCzPacoEI+vu5IVGOO/lj/fGXQcMrwnoe2iaP7kMIHuhvZGieuaiep5C9exF9exB9fwD1WO7iro0TjaNU36eC3e+a3xqheU4dWam3oyKEgryXJyztJoXNzfS0uUMxewXNjdy56vbWL+zOdtNiUvHcMJ6Rfl09IQJxwhLPfzOThZNK+czCyaxcGo5a3eMHePUEOxiUllh32D9uZNKmVVZzCsfJTZOL25uZMGUMmqqjKjYvCmGcfp0b86OzXsIWAlUY8jS/RV42O7K49442c3WAzNMkct9ThtWwq1LQK0w3jeszHaLMkL+h4/xeuE1HHXfXLh1CZdNWEN3KMKzH+zOdtOAfuO584BzS7K0d4dsD8C1iCf+urE2yMa6IF89ZjZCCJYrE3l3R1NMI5ZN/rWlkU31tjOf+2gIdlLt6R/rJITg5IMm8+an++J6x8GOXt7efmBAqLmqtJCKkoLc9ZxAoAbvRw2GzJdVrt0W0jjZKJdhkRPK5PGwBCWDuwC9X1ByrBuoDSs5aqPKTNc+hHncNW9ex+UT1jgmtGeNwdrV1Jlkyeyg6zrtPaE+Y2OXeGUzHl6zk6ICF+ctMxTKjlIqaesOsWV36oYgnfzorxu4bdXHKa+3O9jFNE/RgGmnHDSFjp4w6+KEL1/+eA/hiM4ZUcZJCME8MykiR3kJ1eND9SionhpUz38CAVRPJaonabrsuDZOZe588vPsn4LSwhweVOgUQclMs+omCiJdAyaJ3k6+Jx5m9bb9NASzbxDqmg2PaZdDPaeu3ggR3b4iuUWssYHt3SH+8V4d3kOn94XUlyvGfcpJ/U7NHT0caO9hx/7Uf5OGYBfVg4zTcfOqKMxzxe13en5TI5PL3SybWTFg+vzJZXyau57TVzDGQr2EUWrp2xhK5eswtPkSktq/bQyRijqERbJBhY5mvArDxjm+8u5GdN3omP/WyfMy3KiB1DU7O6zXXy4j9VRyGGicnnq/nvaeMF89pl+tbEZFMdM9RazRDnDp8crIGzwKbDc1GHfs70DXddsFAzt6QgQ7eweE9cAw1EfNmcjLH+3h+s8tHjCvJxThlY/2cs5h1UNqy82fUsaja3fR1N7DxBFqiWYcNThnJKuPW8+ppbM3pf4mMDp4czYhYrwKw8Y5PuGZyeGzK/h7lkN74YhOQ7Ph2TnVc+pTJE+xzylWWO/hd3Zy0NQyjpg9ccCyy5VK1mgHHCMtZRmnzt4we1u7ba8XPQB3MCcfNJmPG9v61Eos3tq2n7buEGcsHjq0Yd4UIzkip0J7RvjO+vzlQfP+y+5mxq1xMjyn1MMUOZtKPk6FYSOn3UCHPuiJ0zzuCw6fwZbdrWxuyF5fR2NLF6GIznRPEXtau+nscd7/qz3FKrgWZW7j4c/ynD6oC/J+bZCLjp49xBM5SplIY0t3X/9bttkepV6/I4WHButBY3CfE8ApC6cA8Mqg0N6LmxspLsjjhPlDx3nNn2yMWc0p42QUjrW4btC8s+xuZJwbp1TDenm5Owh3nArD7ptzLr7eK2grqmbwcXsPrSbfJXhiffa8J+tmfOy8KvO787ynVKvgWljGzPKcHlmzE3e+iwsOH1qqzZKTWpdCSvne1m5+8tiGtAwJ2La3HXe+cXtMpd/J6sOcPiisB7BgShnVnqIBKeW6rvPipkZOWjCJooKhxn/GxGIK8125lrEn4nyO9T0u49Y4tXSGUjZOpYU5nK0HhiH6wQegNhvvY9wwgdGf82TkRN4+75Uhx11V5ubkgybzj/fqsyYRYyVDHDfXME67HGicUq3lZFEe5Tl19IR44r16vIdWU1EytO9k4bRyyt35rNGihGmSDH144K0dPLp2F699vC+1A7LBtn3tHD2nEpeAnfvtjzMaPAA3GiEEpyyczBtb99EbNuSzPqxvoT7YFVetJM8lmDupNNfGOulxPsf6Hpdxa5yG4zmVuvPp7I09qFDiTOrNMIslJTOY8w+fwe6WLt7avj+Tzeqj9oDpOZnGaecwssPSTYcZ1ks1lbzPc+oO8fT7DbR1h7jomNkxl81zCY6omdifsZdk6IOu6zz+npHssqGuOfWDSkAkoqPta+egqeVMryhGS+E3qQ92UVVaGNMLAjj5oCm0dod41/QQX9jUiEvAaYumxN3mvCllueY5HYbqaUH1tAJLzc/W90PtbmRcZuv1hCJ09oZTNk59yuQ9ISYUpbauJDtYnc/xjNMZi6dS5s7niffqsqLtVtfcyaQyNzMnFlNckMfOA87oc4km1RLtFvl5LooL8mjrDvHQOzuZP6WM5TUT4y5/lDKRXz3/McGOXjyJhj4sXcEarYldBzrJcwk27AqmfEyJaGztorM3zJxJpdRUlaTU57Q72El1xdD+JosT5leR7xK8/PFejplbxQubGjmyZiJVZUM9LYv5k8t4ZmMDXb3huEbPUajBUWnkuPScUpUuspDK5LlHXXMnZe78uIOtiwvzOGvJNP65cTddvZlPRqhr7mTGxGKEEMyqLHZkWK+vzynFsB4Y18wa7QDrdzXHTISIxhrvtG7ngaRDHx5/t5aSwjzOWzadD+qCoxqW3W6G0OZOKmV2ZWlKYb2GYBfTJsR+EAIoLyrgyJqJvPLRXuqaO9nU0BIzSy+aeVPK0PWBSRrjgXFtnFJNJe8bVJirSRHjkPrmTqZXFCW8KV5w+Axau0Os2myvrMFoUtvUyUzTq5tdWeLIdPJ+zyl141RelM97O5spzHfxhRiJENEcNrOCfJdgjdaUcOhDV2+YwIYGzl5SzbFzqmjtDqGlYECSsc00AnMml6JUldDU0Ws76SLWANzBnLxwMpsaWnjo7R0ASdXxc14AdphI45QCZVExdEluUB/sZEackJ7FsXOrmDrBnfExT5GITl1zJzMnGu2bZZaPcMpYH4v2njAFeYLC/NRvF1Y/1eeWTEs6iLS4MI8lMzyGxE+CoQ/Pb2qktTvEF4+YwdJZHsAoXDhabN/XTnFBHlPLi6ipMkpV2OkL7BuAmyCsB4aUEcBdr21n7uRS5prGJx5zJ5ciRM6lk4+YtPU5Kb7A3cDngT2a37vEnFYJPAooGGV+V2h+b5M57zrgciAMXKP5vc+lq23LZlXw7s/OpKRweOM2cnas0zikrqmTwwZJwgwmzyXwHjqdB97aQU8oMqyb8HDY19ZNTyjCDMs4TSyhw6w9lagPItO0d4eG5TVBv3G68OjYiRCDOUqZyH2rd9B98Bdxg9HHFKw1PKnTb4ClK3j8nneY7ini2LlVRHSdogIXG2qDnB/tmW1YGXNdO2zf144yqRSXSzC70hgEq+1vZ8kMT8L1dicYgBvN4upyppS72dPabaumWFFBHjMnFkvPaRS5l6EDrnzAKs3vXQCsMr+j+AIHYwzcOsRc5w7FF0hbz1+eS1CZIKMmHqXSc8opOnpCNHX0xk2GiOawWR56whG27cvcDaDWTNawPKfZZiE6p8kYDaeWk8X0imIWTSvnmDlJdT4Bo9+pJxThg7pgzKEPe1q7ePXjvVxwxAxcLkF+notDpnvYUNvcv5ERihxv39fO3EmGUZptek52xjr1q0Mk/r9ZKuUAZybpb7IwquLKPqdRQfN7XwUGV9M9D7jP/HwfcH7U9Ec0v7db83u3A1uBo9PVtuESSytM4lysNPJkYT2ARdMmALCloTWtbYomus4U9N8InaZOPpxaTha/PH8JK686zrY2nZXNtyaOCOyT6+uJ6HDB4f19UktneviwvoWQOXZoJCLHveEIOw90MMc0TmXufCaVFdoK6yWSLhrMpccrXHJcDYfPjp+9GM28yWVs29s2roaxZLrPaarm9zYAmO9Wcv8MYFfUcrXmNEchs/Vyi2Rp5NHMnVxKQZ5gcwbLNljqEFZYz/KgnJYU0d6Tei0ni+LCvJSGXVSVuZk7qZS12uDnWoPH1tVy2KwK5k/p76dZOtNDZ2+437MYgcjxrgMdhCN6n3ECqKkqZceB5F7LblMdYuqE5MZpyQwPN523hDyXPaM9f0oZ3aHIEF2+sYxTxjnF+oViPiIovsCVwJUArvaedLZpCNJzyi36jVPym0VBnov5U8qH7Tk9/m4ti6snsLh6gu116po7qCgp6PtflRTmM6nM7biBuO3dqddyGgnLlYk8v6mRSEQfoNK9qb6FLbtbuem8QwYsf+iMCgDer21m4bRyo48puIsh2BA53ra3P1PPoqayhNXbkg/STjYAdyRYVXG37mljlhn+Hetk2nNqVHyBagDz3crdrQVmRS03E6iPtQHN771T83uXa37v8soMS8i7813ku4T0nHKE+uZOXMLekyzA4mnlwyp419Ub5sePbeAPr3ya0nq1TUMzCWc7cKxT+wjCesNhuVJJc0fvkP6/x9+tpSBPcM7S6QOmz51USpk7n41Wxt4IRI6tsURzozyn2VUl7G7pSjoOLlaRwdHCSicfTxl7mTZOTwKXmp8vBf4RNf1CxRdwK77AHGAB8E6G22aQQM9LCMGXCldz5bpzh1/qfJyWSh8xwzhvtc2dTJtQRIHNgpKLqstpbOmmKUWPfFNDC+GIzke7U/O66pr608gtrHTyjGHjvLb3DD8hYjgcZQ7Gje53CoUjPLG+ntMWTRmSku5yCZbMmMCGOtM42RE5jnPc2/a1U1laOED/r6aqBF1PLsprZ4zTcJlYWkhlaWHmMvZUz92onj2ong+iplWiel5A9XxivtvrMBsmaTNOii/wMLAaWKj4ArWKL3A54AfOVHyBT4Azze9ofu+HwEpgE/AscLXm92Y+XztZls+GldzIH6nobYw9f6Tbl8RmmOfNGICbvL/Joi8pIkUj84F5U/x0b1ufoGcydF03PaeBIZrZlSXUN3fa3s6IsHleR5JKPhyUqhImlRUOEIF97ZN97Gvr5gtHxA7NLZ1Zweb6FnpC5nlLJHKc4Li372sb0N8ERp8TJM/Yawh2Js3UGwnzM1uy/V7iZFujBgdkW6eLtP3jNL/3ojizTo+z/M3Azelqjy2S6Hmx6iaK6Y4/f6Tbl8RmmOetvrmLZbMqbO9mUbVRO2fL7haOM0tY2MEaANob1tm2t93o90hCU0cvnb3hmJ5TRDfqAlnZe2nD5nlt7w5TksGwnhCC5TWVA8q2/+3dWiaWFHDqwtgCqUtnGkMBPm5sTToeKdFxb+/8DSctmDxgVo3Zx5NIALazJ0xzR2/awnpg9Ds9+0FD2rY/ADX4KqpHGTT1POAU8/N9GKXXf5KuJoxLhYi4JMvyGWmp8/FaKn2kDOO8RSI6DcHUPKfJZW6qSgtTTor4oC7YF875qNHeunWDMvUsZk3M4FgnG+e1JxShJxyhLINhPTCSInYe6KCxpYtgZy/Pb2rk3MOmxx0gvdRMirClFBHnuPVgLY0t3UM8p8rSQsrc+Qk19na32E8jHy7zJpfS1NHL/jb7lXnjce1xhZNQPWujXlfaWG0qatCwjsZ7fCn1UUAap2iSlTIfaanz8VoqfaQM47zta+umN6wzw0amnoUQgkXVqSVFdPaE+bixlXOXTSfPJfjI5rpW/8WQhIiqDBonG+e1wxR9LclgWA/6RWDXak08s7GBnlAkbkgPYFZlMRUlBQMH48YjznH3lhmJFnMHGSchBLMrE6uTN5iZoWkN602xkiJGPhj3ltU9+1CDy6Ned454o6OMNE7RJMvyOf0GuoU7/vyRbl8Sm2Gct7oUxjhFs2jaBD5qbLU92HFTQ5CIDstrKpk7qdR2UoTVPstTsjASOERmMvZsnNf2HquWU2ZLNRwyfQJFBS7W7jjA4+/WMm9yKUtnxg/XCSE4dIbHnucU57g3LvoeMDCN3EKZVJIwxT+VAbjDZV72BWAbUT3VAOZ7WpWSpXGKJlmWz9IVPDb9P2lgcuz5I92+JDbDOG996hATUzVO5XT1RthhU+XaSl8+dIaHhdPKbSdT1DaZpTyKB3okeS7BjIrizHhONs5r+zCr4I6UgjwXh8+ayD837maN1sQXj5yZVGVi6UwPHze2Ji99Eue43yg+DQClaqhxml1Zyq6mjrgPLVZ59nT2Oc2oKKaowJXNdPJ42dZpwSmDcJ3D0hUJb3qfTD0bf92hbFQ/m5btS+KQ4nmzyp+n6jlZg2i37G7tV4tOICK6oS7I5HI3Uye4WTStnKc3GBVfBwxajbF+bdNcZpp1nAYzK5OlM5KcV8s4ZXIQrsVRykRWb9uPEHD+suSCMUtnVhCK6GxqaOGIZLJAMY57+6PrTQMw1EusqSqhN6xT39wZcxBsQ7BrWHqdqeByCeZOylBVXNXzMEbywyRUTy1wI0Z29UpUz+XATuDL6WyCNE4pUubOp707hK7rtvXCJJmnvrmLcnd+yhWL508pwyVgS0MLnzu0uj/t2MrustKOAZau4IO6IIfO8CCE4KCpRpbeR7tbOdKq+Bpn/QUF30GfcnbMNsyuLOGZjRnKykqCpcCfyVRyiyPNfqfj51XZesiwwn4ba4PJjVMMtu1rH5IMYVETJcobyzjtDnYxzeZg75Ewf0oZ7+6MrTs4qqjBlLKt04EM66VIqTufiA6dWaiaKrFPXYpjnCyKCvKYO7mMzVZ4LkHacXt3iK172jjUTF22xkkN6HeKs/7FHfcNSSO3mFWZWoG7dGJ5oFVlmVVjATiyZiLzJpfy7yfMsbX8tAlFTCpz876dpIhB6LrO9r1DxzhZJFMnr0/jANxo5k8po665k86esX//kcYpRWTBwdzAqoA7HBZFyxglSLfe1NBCRO9/Yp85sZiSwryBGXtx1p+m74/bH2aVznCCAOw725uoLC0cksGWCcrc+ay69hROt1lWQgjBYTM9/TJGKbC/vYeWrlBc41TtKaYwzxVXAHZ3sDNpkcHRYN5ko2R7Jku7ZAtpnFKkX5l87D+55DKpqkNEs7h6ArsOdNLa1Zsw3To6GQKMPoGDppYPHOsUZ/16vWqIOoRFv3HKvgL12h0HWF4zMWdC2IfO9LB1b1vK+pfb9w0VfI0mzyWYWVnMjn1DHxi6esM0dfSmNY3cYv6UrGfsZQxpnFKkzOFlM558v57rHt/guFLfmSSVIoOxWGQqPHzc2Jow3XpjXZCpE9xMieprWDStnI92t/af/xjrh/OK+N/QivhhvYnO8Jz2tHSxY39Hn9ZdLnDYzAp0vV9Syi7b9w4VfB1MTZyxTlYaeSb6nJRJJbjE6Ix1cjrSOKWIk8tmdPWG+eXTm3j4nV2s2zG8TtPGlq74hjdHRGutNPJ4N/9kLDIz9jY3tCZMt95Q29xXrsFi4bRymjp62dtqjuKPsf5ri2/gyciJccN6npICJhTlZ70i7jumtt1R8arYZvP/EGfflnTRxhSN07Z97RTkCWZOjC8ZVVNVys797UMe/Kw08kyE9dz5ecyuLOHTceA5yWy9FLHCem1dzjNOf3u3lj2t3RTmubjnDa1vlL1d9rd1c/otrwBwweEz+Nqxs/s6+ZNlrTmJ4Q7AtZjuKaK8KL+/3ylG2nFbd4ht+9o597CBKc6Wrt6W3a39HtWg9V9/ehNFBTuoSlDyZXZVSdZLZ6zZfoDigjwOmR6jRlU2/w8J9j156Qqme4rsDcaNYvu+NmqqShMW/6upKqG9J8z+9h4mlfUPxt9tszz7aDEvswKwWUN6TinS1+fU4yzjFApH+OMr2zhsVgWXnaDw7Ie7U66aec8bGu09IU4+aDKPrt3FWb95jS/9/k3+/l4tkRd/PuzS15kmlQq4sRBCsHjahIQaex/WBdGjkiEsYmbsDaKu2ajjlKgfZ9bEDJfOiME7WhNH1FTELjkyglLoIybJvpfOrLAnYxTF9gRp5BY1fRl7A0NqmQzrgdHvtG1f+5gv2S6NU4o4NawX2NjAzgMdXH3KPC4+rgZd1/nL6h2212/t6uW+1RpnHTKN333tCN6+7nR+6l3M/vYefvDo+9BSF3tFB4rW9hUZLHcnXzgOhsZea9y+OytsNFgBu7K0kMnl7oRKEbVNncxIED4CIymi9kAnkSzdgFq6etmyuyV+f1M2RYyT7PvQmR60/R0EO+yl4ocjOtr+jqQZibMrY5fOaAh2MrGkgOLCzEg8zZtcRk8okvU+yXQjjVOKlBU5LyEiEtG546VPWTCljDMWT2XmxBI+e8g0Hn5np+3xEA+8tZPWrhDfOWU+YBQ3u+Kkuaz64ck8eMUxNOVPjr2iA0Vr68wig/k2iwzGYtG0CbR1h6htiu19bjSVyCfHMIALp5bzUWN8Adi65qFFBgczq7KEnnCEPVbfVYZZt6MJXSe+ccqmiHGSfVve7Af19kJ79c2d9IQiST2nWZXFCDHUOBkVcDMT0oP+ku1jPbQnjVOKlJjyJE7qc/rXlj181NjKd06dh8uMmX/jeIVgZy9/fy+OxxNFV2+YP7++jZMWTOLQQWEql0twwvxJVJ17M3p+bojWjiSN3KK/tlNsD2hjbbAvhXwwC6eV80ljW8ywS0dPiAPtPUPUyAczqzKD6uQxWLP9APkuweGzK2IvkE0R4yT7tspn2B2M25dGnsQ4ufPzmO4ZqntY39zF9AwMwLWYn30B2IwgjVOKuFyC0sI82hwyzknXdX738lZmTizmnKXT+6YfPaeSg6sncO+b25Omlf917S72tfVw9anz4y+0dAXi3NtpLaomogt6Smc4VrS2vrkrZcHXwSw0pYi2NAz1gFq7etm2rz2hceoOxRaPteo4JfOcZmfbOGkHOGSGJ77gazZFjJPs21NSQE1Vie3BuDHHOMXJBpxdWYI26Hfd3dKVVsHXwXhKCphU5h7znpPM1hsGpaa+nhN4a9sB3tvZzC/OXzIgjCWE4LITFH782Abe/HQ/J8yfFHP93nCEP7yyjSNmV3BMvJRhi6Ur4KALOOy//8UpM6fwf0sPH81DGRWsIoPeiuoRbafUnU9NVUlMz+mDOsNgDfYyLaxxUh9Fi8ea1No0TkbCRHbGOnX1hnl/V5BLj69JvGA2RYyT7PvQGR7e29lsa1Pb97VT5s5nspWBlyAbsKZqES9sauxbt6s3zIH2noxIF0Vz8bE1GUldzyZZMU6KL6ABrUAYCGl+73LFF6gEHgUUQANWaH5vBhQOU6esKJ82h2Tr3fHyViaVufnykUPj8OccNh3/P7dwzxvb4xqnp96vp665k5vOO8SWCkB5UQEXHj2Lu9/Q8J29KGl4KtPsNYsMjjSsB4aR2RyjeODGumaAuJ7TginlCGGEBM8+dKCRrG22jFPihIjCfBfVE4qyYpw21AbpCUdyavDtYA6bWcHTGxrY39ZNVVnixBhL8LXv/58gG3D24U+wv72nT3k+02nkFt87Y0FG95cNshnWO1Xze5dpfu9y87sPWKX5vQuAVeZ3R1LmzndEn9OG2mZe+2QfV5w0J6ZUf1FBHl87ZjartuyJGWKKRHTuePlTFk0r57RF9isuf8MU4rzvTW3YbU8X1hinVCrgxmPRtAlo+9qHJJVsrGthRkVx3JtecWEeSlXswoN1TZ0U5rn6n9ITMKsyO2Od1piDb1MdJ+ckLK92g43BuNsGC74myAa0aj1Z11MmigyOV5zU53QecJ/5+T7g/Ow1JTGlhc4I693x0qdMKMrna8fMjrvM14+tId8luDeGIXlhcyNb97Tx7VPmpaSdNqOimM8dWs3Db+90XEr9SMc4RbO4upyIDp/sGWhkNtY2x/WaLBYO1tgzqW3qoLqiqC9xJRGzK7Mz1mmNdoD5U8qoTDBI2OksmeFBCNiwK7Fx6uoNU9fcOdA4JcgG7OsLNDP2drekv8jgeCVbxkkHnld8gXWKL3ClOW2q5vc2AJjvMR/lFV/gSsUXWKv4AmsPtPdkqLkDKXXnZ/2mvHVPK89+uJtLj1coT1CzaMqEIryHVvPXtbWGkKmJruvc8dJWaqpK8B6aev/M5SfOobU7xKNrdg2r/eliNI2TNaA2ejBusLMXbX9H3P4mi4XTytH2D/W67KSRW8yqLKGxpTt5ZddRJBzRWac15XRID4zoxrzJZX0h2HjsPNCBrsPc6GSIBNmA1kBczTROllRWpsN644FsGacTNL/3COBs4GrFF/iM3RU1v/dOze9drvm9y7P1ZFdelE9rVyir4qq/f3kbxQV5XGaj1s1lJ8yhrTvEY+v6wxVvbN3P+7VBvvWZecMaD7RsVgVHKRO5543thMKRlNdPF8MtMhiL2ZUlFBfkDeh3+rBuoBJ5PBZOK0eP4XXVNnXa7qezntLjjbVKB1t2t9DaHeLoOakX63MaS2d4eL82mFBJYdveGGnkCbIBy4sKqCwtZKdZOmN3sIuKDA7AHU9kxThpfm+9+b4H+DtwNNCo+ALVAOb7nmy0zQ6HTJ9AXXMnP39qU1ZG8O860MET6+u48OhZtkIvh82q4PDZFdz3ptbX3jte3sqUcjdfPDJ5+et4XH7iXGqbOnk+Knsp29Q1d444jdzC5RIsnFY+wHPakIJxgoHjpLp6w+xt7U6aDGExKwt1ndZsN8Vec9xzAjh10RT2tnajPvlh3AdJK41cGTzGaekK+MEHoDYb71GZgbMrS5ix82m4dQk3rT+R5/TvOFYEOZfJuHFSfIFSxRcotz4D/wZ8ADwJXGoudinwj0y3zS6XnziHy0+cw71vavge35Bxjau7XtuGS8A3T5pre53LTpiDtr+Dlz7aw3s7m3jz0/1886S5uPOH/8R35sFTqakq4U+vbRv2NkabuqaRD8CNZnG1UXjQurltrAsyc2IxE5M8FChVpbjzXXwcZZysznO7ntOsSmO5TPY7rdnRxHRPkW0D6mTOOWw63zp5Lve/tYNbX/wk5jLb97Uxqcydkqf9hfw3uLz5NxDchUBnqr7XSDWXBmpUyYbnNBV4XfEF3gfeAQKa3/ss4AfOVHyBT4Azze+ORAjBT72Lueb0BaxcW8v3HnmP3gyFtva2dvPoml1ccPiMlG7CZy+ZxrQJRdz7psYdL3+Kp7iAryZIpLBDnkvw7yfM4d2dzcMu0THa1AeHXwE3FoumTaCpo7dPRmhjbXCI2Gss8lyCBVPLBiRF1JqZd3Y9u8llbooKXBnznHRdZ832AzmdpTcY31mLWLF8Jrev+oR739g+ZP72fe0D+5tscP6BP1PMIFkph4og5zIZH+ek+b3bgMNiTN8PnJ7p9gwXIQQ/PPMgSgvz+O9/bqGrN8xvv3pEzJTu0eT+t3bQE47wrZPnpbReQZ6Li4+r4f899xEA3z9jQZ/C+kj40pEzueX5j/jz69s4subIEW9vJLR3h2geQZHBWFgDajc3tFCUn8fOAx1cdLQ9o75w6gRe/WRv33e76hAWQoiMZuztPNDBntbu+PWbchAhBP91waE0d/SiPrWJipJCzj+8P5S9fV87Z9gsA29R3h0njO1AEeRcxkmp5DnJt06exy/OO4QXN+/h8vvWpDXFvCcU4eF3dnLKQZOZN0h5wA4XHT0bd76LksI8vnG8MiptKnXn89Vjanj2g91ZV0m2ir6N5sDgvoy93a19SuTJ+pv61y1nb2s3VlZpbVMneS6RUmmFTJbOeMfsbzp6DHlOAPl5Lm6/6HCOnVvJj/76Pi99ZHRnBzt72dfWk1RTbzA9pdNjz3CgCHIuI43TKHDxcQq/+vJhrP50P5fc/Q7BTntS/any7Ie72dvazSXDNCyVpYXccM7B3HTeEipKRi/T8dLja3AJwT1vaKO2zeFQZ6b1jqbn5CkpYLqniC0NLWxIogwxmP6kiBazfamrpc+qLKG2qTMjmaFrtAN4igtYMCX1Bx+nU1SQx12XLGdRdTnffmAd63YcQLMp+DqY7pN/Soc+6PpxqAhyLiON0yjxpSNn8tuvHsGG2ma+etdbpGMM1l/e1KipKuHkBXHKV9jga8fU8KUYUkcjodpTzOeXVvPomp1pM8x2qG8efc8JjLLtW3a38kFdkJqqEjwl9jrPozX2wOhzSjWTcHZlCW3dIZps1iYaCWu0Jo5SJtoaIJyLlBcVcO9lR1PtKeaye9bwzw92A6Tc51R+1EXcqF9JPZOI6ILeshRFkLNZ3j4VVI+G6tmI6lmP6lmb6d1L4zSKfO7Qau68eDlb97Rx/u/eSLkaZyI+rA+ydkcTFx9b48ibxxUnzaW9J8yja3ZmrQ31zUbYbMoIigzGYtG0crbuaePdHc1DigsmYnK5m4klBX3Gqa7J/gBci0yVztjb2s32fe1jKhkiFpPK3Nx/+dEUF+bxh1c+xSX6z7FdhBBsrPwsx3fdztzuB+m9ZkNqhumpawwxWfR+UVmnGig4FTW4DDW4PPmio4s0TqPMqYum8PCVxxIKR/ji79/knjeSl6yww/2rd1BU4OLLR84ahVaOPktmeDh2biX3vKHRHcpOOZG6ppEXGYzFwmnlhCI6u1u6WJqCcRJCcNBUo6JubzjC7pYuZqbo1c3O0FintdrYGd+UjJkTS7j/8mPwFBcwu7JkWMMpLKUIT3FB/LIischmefscQxqnNHDE7Ik8872TOPmgyfz8qU1c9cA62yWjY9Hc0cMT6+u44PAZtkNK2eA7p8ynIdjFDU/EH/SYTuqaRzeN3GJx9YS+z3b7mywWTSvnk8ZWGpq7iOj208gtMjXW6R3tAEUFrpSPL1c5aGo5j3/neG67cHhlXywB2JQFX7NZ3j6Ka48rnITqWRv1ujLGYjrwPKpnXZz5aUUapzRRUVLIXZcs56fexazavAfv/73G+l3Nw9rWX9fW0tUb4eJjlVFt42jzmYMm891T5/Po2l0pK5Z39oS54r41XH7v8DMejTFOo69xNmdSKYWmN3ZIijfvhdMm0N4T5q3t+4HkpTIGU1KYz6SywrR7Tmu0AyybVUFh/vi5JcybXMZhsyqGte5s03NK2Thls7x9FLes7tmHGlwe9bozxmInoAb7ZOZQPbZl5kaD8fNPzAJCCK44aS5/veo4dB2+/Ic3+dNr21LyKiIRnfvf2sHRSiUHT5+QfIUs88MzD+KMxVP5RWAzb2zdZ2udrt4wV96/llVb9vDyx3v5+p/fTtnTDEd0dge70mKcCvJczJ9ShlJVgqc4Nc/Vytj712YjfXk4yRrpLp3R2tXLpvqWMZdCnk5qKg3PaVqqgq/ZLG+fKmqw3nyPlpnLGLISbgY4fPZEnrnmJH702Pv8MrCZt7Yd4JYvH2YrRPfKx3vZeaCDH392YQZaOnJcLsGtXzmML/7+Tb7z4Ls8+d0TqKmKnw3VHQrzrfvX8frWffzvF5dSXlTAfzz8Lhfd9Rb3X3500kJxFq9+snfUigzG4vrPLaY3kroKiGWcXvtkL0IwrOqlsyaWsHrbfh58ewfNHb20dPYS7OylucN4D3b2MnWCmwuPns3pi6ak3Of23s5mInpu12/KNDXD9ZysxIlVNxmhPM9MwzBlq6JwPFRPKeBCDbaan/8NyGjHmMimsvZIWb58ub52bcYzHIeNruvc84bGf/9zMwdXT+DBbx5LWRKVhm/c8w6b6lt4/Sen5VTIZcf+ds773RtMLnPz+HeOj1nWoycU4dsPrGPVlj34v3AoF5rKCy9/tIdv3b+OmROLefCKYxPWyunoCfE//9zCfat3MHdSKQ9feSxTUxjkmglO/J9/UdvUydQJbt6+/oyU17/j5a3877Mf9X1357vwFBfgKS6goqSACUUFfFjfwu6WLqZNKOLCo2dx4VGzbdcYuuX5j/jdS1vZoH426f9RYqDrOv/3r62cv2xGX4gvlxBCrNN1PX4GnuqZi+EtgeHEPIQavDkTbbOQxikLvLCpkaseWMexcyu5+xtHxc0W0va1c8qvXub7Zyzg+2cclOFWjpw3tu7jkrvf4dSFk7nz4uUDUuB7wxGufvBdnt/UyC/PX8LXj60ZsO7b2/Zz+X1rmVhawENXHBsz3XfdjgNcu/J9tP0dXHaCwn9+dpEjSxdccd8aXty8hyNmV/D4d05Ief1QOMKOAx2UufPxFBfElMgKhSOs2rKHB9/eyasf7yXPJThj8RS+dkwNJ86flHD4wVf+uJqOnjBP/ceJKbdNkpskNU4OQD4mZYEzD57K/35xKdf+9X1+8Oh6/u+iI8iLcfO4/60d5LsEX7Wp5eY0Tpg/iZ95F6M+tYlfv/AxPzJDk6FwhO898h7Pb2rk5+ceMsQwARwzt4oHrziGS+5+hy//YTUPXHEM803lgq7eMLe++DF3vbqN6RXFPPzNYzluXlVGjy0VFk4r58XNe4at9J2f50oqV5Wf5+Kzh0zjs4dMY8f+dh56Zyd/XVvLcx82UlNVwpLp8RM53tvVzNePGfobSCTZRBqnLPHFI2fS1NHDLwOb8RR/wH9dsGRAqfSOnhB/XbuLs5ZMY4rDwlSpcOnxCpsbWvntS1tZOK2cs5dM4wcr3+eZjbv5qXcxlyaQYjpsVgWPXHksF//5bb7yx9Xcf/kxhCM6P1y5nk/2tHHR0bP4/7wHOz4UddBUo99ptOpMJaOmqpTrzl7MD888iGc/2M3Ktbtiloy3mDuplHOXxdGLk0iyhLOv6jHOFSfN5UB7D3e8/ClVpYV9ngXAP9bX09IVSnjzzgWEENx0/iF8ureNHz/2Pn9/r45/bdmD7+xFXGGjHtXi6gms/NZxfP1Pb7Pij6vp7A0zqayQey47ilMXTsnAEYycQ8wsy5oUlQhGijs/j/OWzeC8ZcMvKCmRZIvc6WEfo/z4swu56OhZ/Palrfz5daPejK7r3PemxuLqCSyvyf1y2e78PH7/9SOpLCnkX1v28OPPLuSqFEp+zJ1cxsqrjkOZVMJ5y6bz/PdPzhnDBDB/Sjn3fOOoAaUaJBJJYmRChAMIR3SufvBdnv1wNyuP38VhH91OQVsdncXVlH7uJuelmQ6HDSsJvaCS11qPcGr6rEQyTsiFhAjpOTmAPJfgtouW8ePq91my7me42+twCSjtanC6KKQ9TLHL/NY6RG6IXUokkizjuD4nxRc4C7gNyAP+pPm9ji3XPpq48/P4dvhBXGJQqQ1LFDKXvYxEYpe5fFwSiSRtOMpzUnyBPOB3GFpOBwMXKb7AwdltVeZwtdTFnpHr5Z8dInYpkUhyB0cZJwztpq2a37tN83t7gEeA87LcpszhEFHIUWesHpdEIkkbTjNOM4BdUd9rzWnjg1wShUyFsXpcEokkbTitzymWxsqAdELFF7gSuBLAlYZS6FklV0QhU2WsHpdEIkkbTjNOtUB0qdeZQH30AprfeydwJ8DyF2/M3Tz4eCxdMTZv2mP1uCQSSVpwmnFaAyxQfIE5QB1wIfDV7DZJIpFIJJnGUX1Omt8bAr4LPAdsBlZqfu+H2W2VRCKRSDKN0zwnNL/3GeCZbLdDIpFIJNnDUZ6TRCKRSCQgjZNEIpFIHEhOC78KIfYCO4a7vqukYlKko3nfKDZp1JBtGx6ybcNDtm145HDbanRdn5zRBqWKruvj9lXzk6fXZrsNsm2ybU54ybbJtjntJcN6EolEInEc0jhJJBKJxHGMd+N0Z7YbkADZtuEh2zY8ZNuGh2xbmsjphAiJRCKRjE3Gu+ckkUgkEgcijZNEIpFIHIfj5IsygZNLwSu+gAa0AmEgpPm9y7PYlruBzwN7NL93iTmtEngUUAANWKH5vU0OaZsKfBPYay52vSmHlem2zQL+AkwDIsCdmt97mxPOXYK2qWT53Cm+QBHwKuDGuDc9pvm9NzrkvMVrm4oD/nNmG/OAtUCd5vd+3gnnbSSMO88pR0rBn6r5vcuyaZhM7gXOGjTNB6zS/N4FwCrzeza4l6FtA7jVPHfLsnWTAELAtZrfuxg4Frja/I854dzFaxtk/9x1A6dpfu9hwDLgLMUXOBZnnLd4bYPsnzeL72EIZls44bwNm3FnnBjvpeBTQPN7XwUODJp8HnCf+fk+4PxMtskiTtscgeb3Nmh+77vm51aMG8YMHHDuErQt62h+r675vW3m1wLzpeOM8xavbY5A8QVmAl7gT1GTs37eRsJ4NE5OLwWvA88rvsA6s+qv05iq+b0NYNzogClZbs9gvqv4AhsUX+BuxReYmO3GKL6AAhwOvI3Dzt2gtoEDzp3iC+QpvsB6YA/wgub3Oua8xWkbOOC8Ab8B/hMjVGvhiPM2XMajcUpaCj7LnKD5vUdghB2vVnyBz2S7QTnE74F5GGGXBuCWbDZG8QXKgL8B39f83pZstmUwMdrmiHOn+b1hze9dhlEF+2jFF1iSjXbEIk7bsn7eFF/A6ntdl+l9p5PxaJySloLPJprfW2++7wH+jhGGdBKNii9QDWC+78lye/rQ/N5G8wYSAe4ii+dO8QUKMG7+D2p+7+PmZEecu1htc9K5M9vTDLyM0a/oiPNmEd02h5y3E4BzzWSqR4DTFF/gARx23lJlPBqnvlLwii9QiFEK/skstwkAxRcoVXyBcusz8G/AB9lt1RCeBC41P18K/COLbRmAdSGaXECWzp3iCwjgz8Bmze/9ddSsrJ+7eG1zwrlTfIHJii9QYX4uBs4AtuCM8xazbU44b5rfe53m987U/F4F4372L83v/ToOOG8jYdylkmt+b0jxBaxS8HnA3Q4qBT8V+LviC4Dx2zyk+b3PZqsxii/wMHAKMEnxBWqBGwE/sFLxBS4HdgJfdlDbTlF8gWUYYVoN+FY22obxJHsxsNHsowC4Hmecu3htu8gB564auM/MqHUBKzW/92nFF1hN9s9bvLbd74DzFg8n/N+GjZQvkkgkEonjGI9hPYlEIpE4HGmcJBKJROI4pHGSSCQSieOQxkkikUgkjkMaJ4lEIpE4jnGXSi6RxELxBcLAxqhJjyRSq1d8gauADs3v/csI96sByzW/d99ItiORjDWkcZJIDDpNaRpbaH7vH9LYFolk3CONk0SSANOzeRQ41Zz0Vc3v3WrW8WnT/N5fKb7ANcBVGOUoNml+74VmLZ27gblAB3Cl5vduUHyBKuBhYDLwDlFaj4ov8HXgGqAQQ4z1O+asPwPLMQZ63q35vbem8ZAlEkcg+5wkEoNixRdYH/X6StS8Fs3vPRr4LYb682B8wOGa37sUw0gB/Bx4z5x2PUaBPzCULF7X/N7DMeRlZgMovsBi4CsYwr/LMIpNfg1DUHSG5vcu0fzeQ4F7RuuAJRInIz0nicQgUVjv4aj3WF7LBuBBxRd4AnjCnHYi8EUAze/9l+ILVCm+gAf4DPAFc3pA8QWsyqSnA0cCa0z5qmIMoc6ngLmKL/B/QAB4fpjHJ5HkFNI4SSTJ0eN8tvBiGJ1zgZ8pvsAhJC7NEmsbArhP83uvGzxD8QUOAz4LXA2sAP7dftMlktxEhvUkkuR8Jep9dfQMxRdwAbM0v/cljGJvFUAZ8CpGWA7FFzgF2GfWTYqefjZgFadbBXxJ8QWmmPMqFV+gRvEFJgEuze/9G/Az4Ig0HaNE4iik5ySRGBRHqXQDPKv5vT7zs1vxBd7GeJi7aNB6ecADZshOALdqfm+zmTBxj+ILbMBIiLBKF/wceFjxBd4FXsFQi0bzezcpvsBPMaogu4BeDE+p09yO9SA5xLOSSMYiUpVcIkmAHIckkWQHGdaTSCQSieOQnpNEIpFIHIf0nCQSiUTiOKRxkkgkEonjkMZJIpFIJI5DGieJRCKROA5pnCQSiUTiOP5/YpItWC70kZYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# length = len(fit.history['nb_episode_steps'])\n",
    "length = num_episodes\n",
    "fig = plt.figure()\n",
    "#plt.title(\"Reward and Steps to Goal vs. Episodes\")\n",
    "ax = fig.add_subplot(111, label=\"1\")\n",
    "ax2 = fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "ax.plot(range(length), training_steps, color=\"C0\")\n",
    "ax.set_xlabel(\"Episodes\", color=\"C0\")\n",
    "ax.set_ylabel(\"Total Steps\", color=\"C0\")\n",
    "ax.tick_params(axis='x', colors=\"C0\")\n",
    "ax.tick_params(axis='y', colors=\"C0\")\n",
    "ax2.scatter(range(length), training_reward, color=\"C1\")\n",
    "ax2.axes.get_xaxis().set_visible(False)\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel('Episode Reward', color=\"C1\")\n",
    "ax2.yaxis.set_label_position('right')\n",
    "ax2.tick_params(axis='y', colors=\"C1\")\n",
    "ax.set_title(\"Reward and Steps to Goal vs. Episodes\")\n",
    "fig.savefig(f\"Grayscale_{model_type}_{length}eps_{environment_type}\")\n",
    "print(f\"Average Testing Steps for 50 episodes is {total_test_steps / test_episodes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
