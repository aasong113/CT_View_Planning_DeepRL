{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55548b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_teen\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explore_rate(t,min_explore_rate,decay_fact):\n",
    "    return max(min_explore_rate, min(0.8, 1.0 - math.log10((t+1)/decay_fact)))\n",
    "\n",
    "\n",
    "def get_learning_rate(t,min_learning_rate,decay_fact):\n",
    "    return max(min_learning_rate, min(0.8, 1.0 - math.log10((t+1)/decay_fact)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b753b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables: \n",
    "neps = 20\n",
    "tstep = 200\n",
    "min_explore_rate = 0.001\n",
    "min_learning_rate = 0.2\n",
    "#grid_size = tuple((env.observation_space.high + np.ones(env.observation_space.shape)).astype(int))\n",
    "#decay_fact = np.prod(grid_size, dtype=float) / 10.0\n",
    "decay_fact = np.prod((405,405),dtype=float)/10.0\n",
    "#state_bounds = list(zip(env.observation_space.low, env.observation_space.high))\n",
    "explore_rate = get_explore_rate(0,min_explore_rate,decay_fact)\n",
    "learning_rate = get_learning_rate(0,min_learning_rate,decay_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = np.prod((405,405),dtype=int)*100\n",
    "streak_to_end = 3\n",
    "solved_t = np.prod((405,405),dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf53518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(env,state, q_table,explore_rate):\n",
    "    # Select a random action\n",
    "    if random.random() < explore_rate:\n",
    "        action = env.action_space.sample()\n",
    "    # Select the action with the highest q\n",
    "    else:\n",
    "        action = int(np.argmax(q_table[state]))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ee2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_bucket(state,env):\n",
    "    grid_size = tuple((env.observation_space.high + np.ones(env.observation_space.shape)).astype(int))\n",
    "    state_bounds = list(zip(env.observation_space.low, env.observation_space.high))\n",
    "    bucket_indice = []\n",
    "    for i in range(len(state)):\n",
    "        if state[i] <= state_bounds[i][0]:\n",
    "            bucket_index = 0\n",
    "        elif state[i] >= state_bounds[i][1]:\n",
    "            bucket_index = grid_size[i] - 1\n",
    "        else:\n",
    "            # Mapping the state bounds to the bucket array\n",
    "            bound_width = state_bounds[i][1] - state_bounds[i][0]\n",
    "            offset = (grid_size[i]-1)*state_bounds[i][0]/bound_width\n",
    "            scaling = (grid_size[i]-1)/bound_width\n",
    "            bucket_index = int(round(scaling*state[i] - offset))\n",
    "        bucket_indice.append(bucket_index)\n",
    "    return tuple(bucket_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qlearn(env,q_table, explore_rate, learning_rate, neps=1,tstep=1):\n",
    "    env.render()\n",
    "    num_streaks = 0\n",
    "    discount_factor = 0.99\n",
    "    max_t = np.prod((405,405),dtype=int)*100\n",
    "    streak_to_end = 100\n",
    "    solved_t = np.prod((405,405),dtype=int)\n",
    "    decay_fact = np.prod((405,405),dtype=float)/10.0\n",
    "    frames = []\n",
    "    \n",
    "    for ep in range(neps):\n",
    "        if ep == 0:\n",
    "            time.sleep(1)\n",
    "        obv = env.reset()\n",
    "        print('------------'+str(ep))\n",
    "        state_0 = state_to_bucket(obv,env)\n",
    "        total_reward = 0\n",
    "        \n",
    "        for t in range(tstep):\n",
    "            # select best action and execute\n",
    "            action = select_action(env,state_0, q_table, explore_rate)\n",
    "            try: \n",
    "                obv,reward,done,_ = env.step(action)\n",
    "                # print(obv.shape)\n",
    "                # print(obv)\n",
    "            except(IndexError):\n",
    "                # print(action)\n",
    "                # print(state_0)\n",
    "                break\n",
    "            \n",
    "            # update the state you are in, add reward (observe result)\n",
    "            state = state_to_bucket(obv,env)\n",
    "            total_reward += reward\n",
    "            #print(reward)\n",
    "            #print('cur' + str(reward))\n",
    "            #print(total_reward)\n",
    "            #print(reward, total_reward)\n",
    "            \n",
    "            # update Q-table\n",
    "            best_q = np.amax(q_table[state])\n",
    "            q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * (best_q) - q_table[state_0 + (action,)])\n",
    "            \n",
    "            # update state\n",
    "            state_0 = state\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            frames.append(env.render())\n",
    "            # plt.imshow(frame1)\n",
    "            # plt.title(f\"frame\")\n",
    "            # plt.show()\n",
    "            #time.sleep(0.0000001)\n",
    "            \n",
    "            \n",
    "            # update parameters\n",
    "            #explore_rate = get_explore_rate(ep,min_explore_rate,decay_fact)\n",
    "            #learning_rate = get_learning_rate(ep,min_learning_rate,decay_fact)\n",
    "            \n",
    "            if done:\n",
    "                time.sleep(1)\n",
    "                print(\"Episode %d finished after %f time steps with total reward = %f (streak %d).\"\n",
    "                      % (ep, t, total_reward, num_streaks))\n",
    "\n",
    "                if t <= solved_t:\n",
    "                    num_streaks += 1\n",
    "                else:\n",
    "                    num_streaks = 0\n",
    "                break\n",
    "\n",
    "            elif t >= max_t - 1:\n",
    "                print(\"Episode %d timed out at %d with total reward = %f.\"\n",
    "                      % (ep, t, total_reward))\n",
    "\n",
    "        # It's considered done when it's solved over 120 times consecutively\n",
    "        if num_streaks > streak_to_end:\n",
    "            break\n",
    "            \n",
    "        explore_rate = get_explore_rate(ep,0.001,decay_fact)\n",
    "        learning_rate = get_learning_rate(ep,0.2,decay_fact)\n",
    "                \n",
    "    return q_table, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table0 = np.zeros((405,405) + (4,), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5a22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env1 = gym.make('maze-v0',height=60,width=60)\n",
    "#fin_q_table, frames1 = run_qlearn(env1,q_table0,explore_rate,learning_rate,neps=100,tstep=max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d299e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.choice(env1.action_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b48780",
   "metadata": {},
   "source": [
    "# Torch DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddf0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_teen\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import gym\n",
    "from simple_dqn_torch import Agent\n",
    "from utils import plot_learning_curve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = gym.make('maze-v0',height=60,width=60)\n",
    "print(env1.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation1 = env1.reset()\n",
    "score = 0\n",
    "print(observation1.shape[0])\n",
    "\n",
    "agent2 = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
    "                  input_dims=[2], lr=0.001)\n",
    "\n",
    "action = agent2.choose_action(observation1)\n",
    "print(action)\n",
    "action = agent2.choose_action(observation1)\n",
    "print(action)\n",
    "action = agent2.choose_action(observation1)\n",
    "print(action)\n",
    "action = agent2.choose_action(observation1)\n",
    "print(action)\n",
    "\n",
    "#action = env1.action_space.sample()\n",
    "\n",
    "#observation_, reward, done, info = env1.step(action)\n",
    "\n",
    "observation_, reward, done, info = env1.step(action)\n",
    "agent2.store_transition(observation1, action, reward, \n",
    "                        observation_, done)\n",
    "agent2.learn()\n",
    "observation1 = observation_\n",
    "\n",
    "score += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a8815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xzhao/Desktop/RL_DL/gym-teen_2/simple_dqn_torch.py:74: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1640812094853/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  state = T.tensor([observation]).float().to(self.Q_eval.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score -107155.26 average score -107155.26 epsilon 0.29\n",
      "episode  1 score -834158.42 average score -470656.84 epsilon 0.01\n",
      "episode  2 score -826664.86 average score -589326.18 epsilon 0.01\n",
      "episode  3 score -843644.51 average score -652905.76 epsilon 0.01\n",
      "episode  4 score -809607.88 average score -684246.19 epsilon 0.01\n",
      "episode  5 score -787478.00 average score -701451.49 epsilon 0.01\n",
      "episode  6 score -989187.42 average score -742556.62 epsilon 0.01\n",
      "episode  7 score -874746.64 average score -759080.37 epsilon 0.01\n",
      "episode  8 score -953872.91 average score -780723.99 epsilon 0.01\n",
      "episode  9 score -783582.86 average score -781009.88 epsilon 0.01\n",
      "episode  10 score -611.94 average score -710064.61 epsilon 0.01\n",
      "episode  11 score -899339.00 average score -725837.48 epsilon 0.01\n",
      "episode  12 score -989520.09 average score -746120.75 epsilon 0.01\n",
      "episode  13 score -774837.25 average score -748171.93 epsilon 0.01\n",
      "episode  14 score -848837.77 average score -754882.99 epsilon 0.01\n",
      "episode  15 score -988344.99 average score -769474.36 epsilon 0.01\n",
      "episode  16 score -938612.46 average score -779423.66 epsilon 0.01\n",
      "episode  17 score -865083.26 average score -784182.53 epsilon 0.01\n",
      "episode  18 score -853249.81 average score -787817.65 epsilon 0.01\n",
      "episode  19 score -957285.88 average score -796291.06 epsilon 0.01\n",
      "episode  20 score -814012.95 average score -797134.96 epsilon 0.01\n",
      "episode  21 score -956424.13 average score -804375.38 epsilon 0.01\n",
      "episode  22 score -929095.06 average score -809797.97 epsilon 0.01\n",
      "episode  23 score -988326.66 average score -817236.67 epsilon 0.01\n",
      "episode  24 score -981954.48 average score -823825.38 epsilon 0.01\n",
      "episode  25 score -740324.97 average score -820613.83 epsilon 0.01\n",
      "episode  26 score -847.43 average score -790252.11 epsilon 0.01\n",
      "episode  27 score -751566.65 average score -788870.48 epsilon 0.01\n",
      "episode  28 score -780710.08 average score -788589.09 epsilon 0.01\n",
      "episode  29 score -970647.79 average score -794657.71 epsilon 0.01\n",
      "episode  30 score -786147.81 average score -794383.20 epsilon 0.01\n",
      "episode  31 score -433.56 average score -769572.27 epsilon 0.01\n",
      "episode  32 score -954554.83 average score -775177.81 epsilon 0.01\n",
      "episode  33 score -824007.46 average score -776613.97 epsilon 0.01\n",
      "episode  34 score -623406.10 average score -772236.60 epsilon 0.01\n",
      "episode  35 score -601519.69 average score -767494.47 epsilon 0.01\n",
      "episode  36 score -666753.83 average score -764771.75 epsilon 0.01\n",
      "episode  37 score -683752.42 average score -762639.66 epsilon 0.01\n",
      "episode  38 score -661961.96 average score -760058.18 epsilon 0.01\n",
      "episode  39 score -570581.81 average score -755321.27 epsilon 0.01\n",
      "episode  40 score -722229.72 average score -754514.16 epsilon 0.01\n",
      "episode  41 score -989682.57 average score -760113.41 epsilon 0.01\n",
      "episode  42 score -920374.03 average score -763840.40 epsilon 0.01\n",
      "episode  43 score -933170.19 average score -767688.80 epsilon 0.01\n",
      "episode  44 score -943474.36 average score -771595.15 epsilon 0.01\n",
      "episode  45 score -941243.09 average score -775283.15 epsilon 0.01\n",
      "episode  46 score -959045.09 average score -779192.98 epsilon 0.01\n",
      "episode  47 score -927222.16 average score -782276.92 epsilon 0.01\n",
      "episode  48 score -955136.01 average score -785804.65 epsilon 0.01\n",
      "episode  49 score -328.70 average score -770095.14 epsilon 0.01\n",
      "episode  50 score -956786.56 average score -773755.75 epsilon 0.01\n",
      "episode  51 score -951717.66 average score -777178.10 epsilon 0.01\n",
      "episode  52 score -957681.81 average score -780583.83 epsilon 0.01\n",
      "episode  53 score -846866.38 average score -781811.28 epsilon 0.01\n",
      "episode  54 score -944384.79 average score -784767.16 epsilon 0.01\n",
      "episode  55 score -949923.06 average score -787716.38 epsilon 0.01\n",
      "episode  56 score -913457.20 average score -789922.36 epsilon 0.01\n",
      "episode  57 score -867282.80 average score -791256.16 epsilon 0.01\n",
      "episode  58 score -989187.42 average score -794610.92 epsilon 0.01\n",
      "episode  59 score -922031.40 average score -796734.60 epsilon 0.01\n",
      "episode  60 score -931634.62 average score -798946.07 epsilon 0.01\n",
      "episode  61 score -939555.32 average score -801213.96 epsilon 0.01\n",
      "episode  62 score -923800.60 average score -803159.78 epsilon 0.01\n",
      "episode  63 score -870366.10 average score -804209.88 epsilon 0.01\n",
      "episode  64 score -849012.62 average score -804899.16 epsilon 0.01\n",
      "episode  65 score -874383.52 average score -805951.95 epsilon 0.01\n",
      "episode  66 score -936445.40 average score -807899.61 epsilon 0.01\n",
      "episode  67 score -918578.96 average score -809527.25 epsilon 0.01\n",
      "episode  68 score -989492.58 average score -812135.44 epsilon 0.01\n",
      "episode  69 score -804157.95 average score -812021.48 epsilon 0.01\n",
      "episode  70 score -650549.60 average score -809747.23 epsilon 0.01\n",
      "episode  71 score -912624.77 average score -811176.08 epsilon 0.01\n",
      "episode  72 score -72121.75 average score -801052.05 epsilon 0.01\n",
      "episode  73 score -720786.00 average score -799967.37 epsilon 0.01\n",
      "episode  74 score -651.77 average score -789309.83 epsilon 0.01\n",
      "episode  75 score -883.32 average score -778935.80 epsilon 0.01\n",
      "episode  76 score -812780.03 average score -779375.34 epsilon 0.01\n",
      "episode  77 score -881077.54 average score -780679.21 epsilon 0.01\n",
      "episode  78 score -899855.06 average score -782187.76 epsilon 0.01\n",
      "episode  79 score -800113.69 average score -782411.84 epsilon 0.01\n",
      "episode  80 score -982247.35 average score -784878.94 epsilon 0.01\n",
      "episode  81 score -893199.28 average score -786199.92 epsilon 0.01\n",
      "episode  82 score -959295.06 average score -788285.41 epsilon 0.01\n",
      "episode  83 score -873201.52 average score -789296.31 epsilon 0.01\n",
      "episode  84 score -910606.77 average score -790723.49 epsilon 0.01\n",
      "episode  85 score -849484.09 average score -791406.76 epsilon 0.01\n",
      "episode  86 score -989994.79 average score -793689.38 epsilon 0.01\n",
      "episode  87 score -911100.18 average score -795023.59 epsilon 0.01\n",
      "episode  88 score -983172.57 average score -797137.63 epsilon 0.01\n",
      "episode  89 score -916062.18 average score -798459.01 epsilon 0.01\n",
      "episode  90 score -571207.86 average score -795961.74 epsilon 0.01\n",
      "episode  91 score -864205.42 average score -796703.52 epsilon 0.01\n",
      "episode  92 score -270094.67 average score -791041.06 epsilon 0.01\n",
      "episode  93 score -985496.36 average score -793109.74 epsilon 0.01\n",
      "episode  94 score -985930.75 average score -795139.43 epsilon 0.01\n",
      "episode  95 score -979166.35 average score -797056.38 epsilon 0.01\n",
      "episode  96 score -978844.33 average score -798930.48 epsilon 0.01\n",
      "episode  97 score -968364.05 average score -800659.39 epsilon 0.01\n",
      "episode  98 score -768940.10 average score -800339.00 epsilon 0.01\n",
      "episode  99 score -1797.35 average score -792353.58 epsilon 0.01\n",
      "episode  100 score -995.96 average score -791291.99 epsilon 0.01\n",
      "episode  101 score -852660.62 average score -791477.01 epsilon 0.01\n",
      "episode  102 score -963089.01 average score -792841.25 epsilon 0.01\n",
      "episode  103 score -769072.24 average score -792095.53 epsilon 0.01\n",
      "episode  104 score -125939.07 average score -785258.84 epsilon 0.01\n",
      "episode  105 score -988668.52 average score -787270.75 epsilon 0.01\n",
      "episode  106 score -961264.73 average score -786991.52 epsilon 0.01\n",
      "episode  107 score -629797.96 average score -784542.03 epsilon 0.01\n",
      "episode  108 score -792193.16 average score -782925.23 epsilon 0.01\n",
      "episode  109 score -980512.34 average score -784894.53 epsilon 0.01\n",
      "episode  110 score -980326.91 average score -794691.68 epsilon 0.01\n",
      "episode  111 score -663981.96 average score -792338.11 epsilon 0.01\n",
      "episode  112 score -716814.65 average score -789611.05 epsilon 0.01\n",
      "episode  113 score -987646.39 average score -791739.15 epsilon 0.01\n",
      "episode  114 score -762805.39 average score -790878.82 epsilon 0.01\n",
      "episode  115 score -927439.79 average score -790269.77 epsilon 0.01\n",
      "episode  116 score -860353.70 average score -789487.18 epsilon 0.01\n",
      "episode  117 score -912208.91 average score -789958.44 epsilon 0.01\n",
      "episode  118 score -884553.49 average score -790271.48 epsilon 0.01\n",
      "episode  119 score -897713.98 average score -789675.76 epsilon 0.01\n",
      "episode  120 score -894291.73 average score -790478.54 epsilon 0.01\n",
      "episode  121 score -915003.24 average score -790064.34 epsilon 0.01\n",
      "episode  122 score -850181.54 average score -789275.20 epsilon 0.01\n",
      "episode  123 score -892413.58 average score -788316.07 epsilon 0.01\n",
      "episode  124 score -984751.82 average score -788344.04 epsilon 0.01\n",
      "episode  125 score -850048.39 average score -789441.28 epsilon 0.01\n",
      "episode  126 score -977698.18 average score -799209.79 epsilon 0.01\n",
      "episode  127 score -851701.93 average score -800211.14 epsilon 0.01\n",
      "episode  128 score -945070.65 average score -801854.74 epsilon 0.01\n",
      "episode  129 score -976409.79 average score -801912.36 epsilon 0.01\n",
      "episode  130 score -809421.25 average score -802145.10 epsilon 0.01\n",
      "episode  131 score -958860.45 average score -811729.37 epsilon 0.01\n",
      "episode  132 score -951566.79 average score -811699.49 epsilon 0.01\n",
      "episode  133 score -987925.86 average score -813338.67 epsilon 0.01\n",
      "episode  134 score -941981.54 average score -816524.42 epsilon 0.01\n",
      "episode  135 score -987747.74 average score -820386.71 epsilon 0.01\n",
      "episode  136 score -989842.52 average score -823617.59 epsilon 0.01\n",
      "episode  137 score -900556.54 average score -825785.63 epsilon 0.01\n",
      "episode  138 score -986399.20 average score -829030.01 epsilon 0.01\n",
      "episode  139 score -870555.55 average score -832029.74 epsilon 0.01\n",
      "episode  140 score -972863.86 average score -834536.08 epsilon 0.01\n",
      "episode  141 score -945696.03 average score -834096.22 epsilon 0.01\n",
      "episode  142 score -880.81 average score -824901.29 epsilon 0.01\n",
      "episode  143 score -660089.42 average score -822170.48 epsilon 0.01\n",
      "episode  144 score -887858.94 average score -821614.33 epsilon 0.01\n",
      "episode  145 score -756318.31 average score -819765.08 epsilon 0.01\n",
      "episode  146 score -940205.07 average score -819576.68 epsilon 0.01\n",
      "episode  147 score -915977.01 average score -819464.23 epsilon 0.01\n",
      "episode  148 score -849850.43 average score -818411.37 epsilon 0.01\n",
      "episode  149 score -855953.74 average score -826967.62 epsilon 0.01\n",
      "episode  150 score -880022.62 average score -826199.98 epsilon 0.01\n",
      "episode  151 score -851697.44 average score -825199.78 epsilon 0.01\n",
      "episode  152 score -850920.43 average score -824132.17 epsilon 0.01\n",
      "episode  153 score -944177.49 average score -825105.28 epsilon 0.01\n",
      "episode  154 score -888087.42 average score -824542.30 epsilon 0.01\n",
      "episode  155 score -985675.66 average score -824899.83 epsilon 0.01\n",
      "episode  156 score -988689.15 average score -825652.15 epsilon 0.01\n",
      "episode  157 score -930233.09 average score -826281.65 epsilon 0.01\n",
      "episode  158 score -859359.47 average score -824983.37 epsilon 0.01\n",
      "episode  159 score -852295.62 average score -824286.01 epsilon 0.01\n",
      "episode  160 score -971940.11 average score -824689.07 epsilon 0.01\n",
      "episode  161 score -962125.58 average score -824914.77 epsilon 0.01\n",
      "episode  162 score -953043.16 average score -825207.20 epsilon 0.01\n",
      "episode  163 score -772101.60 average score -824224.55 epsilon 0.01\n",
      "episode  164 score -896193.84 average score -824696.36 epsilon 0.01\n",
      "episode  165 score -973064.91 average score -825683.18 epsilon 0.01\n",
      "episode  166 score -838843.58 average score -824707.16 epsilon 0.01\n",
      "episode  167 score -906503.81 average score -824586.41 epsilon 0.01\n",
      "episode  168 score -913992.24 average score -823831.40 epsilon 0.01\n",
      "episode  169 score -831171.43 average score -824101.54 epsilon 0.01\n",
      "episode  170 score -962555.71 average score -827221.60 epsilon 0.01\n",
      "episode  171 score -651431.27 average score -824609.67 epsilon 0.01\n",
      "episode  172 score -298.59 average score -823891.43 epsilon 0.01\n",
      "episode  173 score -988597.47 average score -826569.55 epsilon 0.01\n",
      "episode  174 score -152158.45 average score -828084.62 epsilon 0.01\n",
      "episode  175 score -879015.63 average score -836865.94 epsilon 0.01\n",
      "episode  176 score -862498.45 average score -837363.12 epsilon 0.01\n",
      "episode  177 score -485818.14 average score -833410.53 epsilon 0.01\n",
      "episode  178 score -869502.01 average score -833107.00 epsilon 0.01\n",
      "episode  179 score -969956.97 average score -834805.43 epsilon 0.01\n",
      "episode  180 score -933981.61 average score -834322.77 epsilon 0.01\n",
      "episode  181 score -966314.32 average score -835053.92 epsilon 0.01\n",
      "episode  182 score -928210.40 average score -834743.08 epsilon 0.01\n",
      "episode  183 score -888855.45 average score -834899.62 epsilon 0.01\n",
      "episode  184 score -871724.44 average score -834510.79 epsilon 0.01\n",
      "episode  185 score -954775.78 average score -835563.71 epsilon 0.01\n",
      "episode  186 score -850904.82 average score -834172.81 epsilon 0.01\n",
      "episode  187 score -928295.10 average score -834344.76 epsilon 0.01\n",
      "episode  188 score -977767.76 average score -834290.71 epsilon 0.01\n",
      "episode  189 score -887825.62 average score -834008.35 epsilon 0.01\n",
      "episode  190 score -924983.77 average score -837546.11 epsilon 0.01\n",
      "episode  191 score -983252.28 average score -838736.57 epsilon 0.01\n",
      "episode  192 score -920965.88 average score -845245.29 epsilon 0.01\n",
      "episode  193 score -877677.17 average score -844167.09 epsilon 0.01\n",
      "episode  194 score -873264.91 average score -843040.44 epsilon 0.01\n",
      "episode  195 score -987554.80 average score -843124.32 epsilon 0.01\n",
      "episode  196 score -927721.15 average score -842613.09 epsilon 0.01\n",
      "episode  197 score -538109.89 average score -838310.55 epsilon 0.01\n",
      "episode  198 score -982908.91 average score -840450.23 epsilon 0.01\n",
      "episode  199 score -989017.15 average score -850322.43 epsilon 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    env = gym.make('maze-v0',height=60,width=60)    \n",
    "\n",
    "    agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
    "                  input_dims=[2], lr=0.001)\n",
    "    scores, eps_history = [], []\n",
    "    n_games = 200\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, \n",
    "                                    observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "\n",
    "        print('episode ', i, 'score %.2f' % score,\n",
    "                'average score %.2f' % avg_score,\n",
    "                'epsilon %.2f' % agent.epsilon)\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    filename = 'lunar_lander.png'\n",
    "    plot_learning_curve(x, scores, eps_history, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar Landing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "  env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494536a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "done = False\n",
    "observation = env.reset()\n",
    "print(observation)\n",
    "\n",
    "agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
    "                  input_dims=[8], lr=0.001)\n",
    "\n",
    "action = agent.choose_action(observation)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26044c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = 0\n",
    "done = False\n",
    "observation = env.reset()\n",
    "    \n",
    "action = agent.choose_action(observation)\n",
    "observation_, reward, done, info = env.step(action)\n",
    "score += reward\n",
    "agent.store_transition(observation, action, reward, \n",
    "                        observation_, done)\n",
    "agent.learn()\n",
    "observation = observation_\n",
    "scores.append(score)\n",
    "eps_history.append(agent.epsilon)\n",
    "\n",
    "        avg_score = np.mean(scores[-100:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=4, eps_end=0.01,\n",
    "                  input_dims=[8], lr=0.001)\n",
    "    scores, eps_history = [], []\n",
    "    n_games = 1\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, \n",
    "                                    observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "\n",
    "        print('episode ', i, 'score %.2f' % score,\n",
    "                'average score %.2f' % avg_score,\n",
    "                'epsilon %.2f' % agent.epsilon)\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    filename = 'lunar_lander.png'\n",
    "    plotLearning(x, scores, eps_history, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7c3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77556c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d9f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f108a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from rl.agents import DQNAgent\n",
    "\n",
    "# knowledge buffer from previous games\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "# Greedy is what allows us to find the best outcome, Linear is what allows us to optimize the strategy. \n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34240e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the states from our environment, and the actions from our environment. \n",
    "# number of frames or instances in the input. \n",
    "def build_model(height, width, channels, actions, window_length):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 3 convolutional layers. \n",
    "    model.add(Convolution2D(32,(8,8),strides=(4,4), activation='relu', input_shape=(window_length,height,width, channels)))\n",
    "    model.add(Convolution2D(64,(4,4),strides=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,(3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # 3 dense layers\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    # takes image to an output of actions. \n",
    "    model.add(Dense(actions, activations='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions, window_length2):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.2, nb_steps=10000)\n",
    "    memory = SequentialMemory(limit=1000, window_length=window_length2)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  enable_dueling_network=True, dueling_type='avg', \n",
    "                   nb_actions=actions, nb_steps_warmup=1000\n",
    "                  )\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9620aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64c0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073075a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
